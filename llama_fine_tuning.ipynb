{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "MAX_SEQ_LENGTH = 2048\n",
        "D_TYPE = None\n",
        "LOAD_IN_4BIT = True\n",
        "\n",
        "SEED = 3407\n",
        "COARSE_TRIALS = 12\n",
        "COARSE_DATASET_SIZE = 1000\n",
        "FINE_TRIALS = 4\n",
        "FINE_DATASET_SIZE = 3000\n",
        "\n",
        "BASE_MODEL_NAME = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
        "CHAT_TEMPLATE = \"llama-3.1\"\n",
        "drive.mount('/content/drive')\n",
        "CHECKPOINT_DIR = f'/content/drive/MyDrive/{BASE_MODEL_NAME}'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHBm8Nlr1vZi",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997287445,
          "user_tz": -60,
          "elapsed": 20724,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "19bf195a-7370-4c74-fa43-aad32af41f82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2eSvM9zX_2d3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997522242,
          "user_tz": -60,
          "elapsed": 234795,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        }
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth optuna sentence-transformers rouge-score plotly\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git@nightly git+https://github.com/unslothai/unsloth-zoo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HgPaIRW6pXIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997530648,
          "user_tz": -60,
          "elapsed": 8404,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "4a09834a-8ece-42a7-a5b0-add4388d3de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: wandb 0.23.0\n",
            "Uninstalling wandb-0.23.0:\n",
            "  Successfully uninstalled wandb-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall wandb -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZwDHkBFtPR1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997582262,
          "user_tz": -60,
          "elapsed": 51613,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "a75743e0-422b-45b6-847c-fa626063507a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import optuna\n",
        "import random\n",
        "import gc\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from unsloth.chat_templates import train_on_responses_only, standardize_sharegpt, get_chat_template\n",
        "from datasets import load_dataset, concatenate_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtTLhR-8VS5K"
      },
      "source": [
        "## Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmUBVEnvCDJv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "9242cae9f054485d80c44c4a2f979783",
            "56ac8e98a1fb445da35a0a4abb50b277",
            "9eef1043f3304bc4b590c55afa6d3bb0",
            "167c4a20da83434a96e8f8ee08e0df2f",
            "a3cacc65a20542058f19c1d18198c6f7",
            "19d4144a02bf40b483c7e492c6dd2900",
            "753f81a0a86d4c97968153628612164b",
            "b38cfe1474fd4b578b880f38ab265448",
            "4b5f02e3b3924d56a19e34d8e2be157c",
            "5da521c89f1445998f32c9729c84364a",
            "4c1e179569584b89a35c7dc19d69c458",
            "7685312ee7db403ca0081c42c9e301ca",
            "2a696f5b46b248698ebe311172e47fcb",
            "e8ca939bae3a44ba9f10886c2eecd363",
            "3d89b9444b304dea8ed73d0265868fbb",
            "e329b7b6a4c944e986de27eceb3569ec",
            "b77092e1b3bf45ff9b92869496222351",
            "6e73149ba93642cc8d0bad86ae36824d",
            "0dc5fbb1a81f4f51b9b568a45b2290f0",
            "b17a2fce112246378c0cb9462b9630d7",
            "c9cf615aacac48a388e4528b765e832c",
            "f16ddfa09b2d478ebe102d432c9f678f",
            "7da70c7410ed419e9976527978d261be",
            "d6327873affb45e78fee453792c1580a",
            "f4b1ade04580403fa331206d0f0d4f1a",
            "cd56cd165a0c426aacc25a34dd87241b",
            "292c47701b7e414a9478ffe8c546f66f",
            "2d064f55649b45b493c15d09d054a552",
            "8e4b5b799bce4cb9bdd548df5adc085a",
            "e4a0c7e042714186a1d8a705979e0d76",
            "209d38fae3a54bd889bb1828d049c82d",
            "23b8f74941f540a99656afc8fc9534ce",
            "8ac2b4e7dec44ad793d8fbe78568c4b3",
            "30b08ea7939349079fae847e001dbbff",
            "4544293a20864a5a820e90fa78a495bf",
            "1aea632aafcb49f3ab868c686d3a271d",
            "e75253048ccf42c68a33584d6a60fcde",
            "4dc546102489418dbdc0b9ecf8e6e2ce",
            "e253b199906c42beb4c28e7105621a76",
            "b2e2d90235224a9182e325221fa6cd77",
            "5a358ca449154bc794206f6fe6f99cd3",
            "6aefade4cdbf436f8fbfae00a141ac86",
            "f11bb30db5244a0e83dc7d34ab90d540",
            "a09d8a7a539c49e3bafc2e58bb6649aa",
            "b5dd1047394b447a9b7236ade9a93711",
            "da2baf0aef7947df9549081b22520fdf",
            "9a6975096368473aa3e5fbd546402a76",
            "a6edc9b917684d4b86a9f0ec7565c1e7",
            "abdffa097c2743b3b5020f9f23b80592",
            "4f0ec8709bde42d1bd0c68157302d568",
            "961449022eea45b38c9965fb34867320",
            "c90b77075e05484489ad97080645c6bc",
            "d2e3bd95d3424fc38f2ca135d52108b7",
            "5adc1492050f434b809d5cf44440002f",
            "ed28bb29a9d44b89b8bfec544b840efe",
            "3d2e52468aaf4ca2a2c9068c47dcb342",
            "91683429530c4a618af0289ab0d1a63c",
            "6c9ac944f8c340349630cc3ea9dfc0a5",
            "dd8a9491e5a94ddd9d8d5deb37f72905",
            "2a00bb2c97264952a94910325c5d5cb9",
            "8dc02ef2d5be4c3d9580f78acb44ec35",
            "1fe4cfc4389047d8a872052b418399a7",
            "cc109a6a86e9437ca65cccbdc5ff2008",
            "99556a454ebe41efbdaa198defe845ad",
            "5de903cb258847fa8b8bf2249d1e2222",
            "f50d84483a6f4614b97724657f161b61"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997621161,
          "user_tz": -60,
          "elapsed": 38896,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "de44b9c0-b3ff-48a4-da7c-91472127e25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.11.6: Fast Llama patching. Transformers: 4.57.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9242cae9f054485d80c44c4a2f979783"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7685312ee7db403ca0081c42c9e301ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7da70c7410ed419e9976527978d261be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30b08ea7939349079fae847e001dbbff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5dd1047394b447a9b7236ade9a93711"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d2e52468aaf4ca2a2c9068c47dcb342"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initial load for tokenizer and basic setup\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = BASE_MODEL_NAME,\n",
        "    max_seq_length = MAX_SEQ_LENGTH,\n",
        "    dtype = D_TYPE,\n",
        "    load_in_4bit = LOAD_IN_4BIT,\n",
        ")\n",
        "\n",
        "# Chat Template and Tokenizer Setup\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = CHAT_TEMPLATE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psn_AcDVAUuQ"
      },
      "source": [
        "## Data Preparations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qplYttP_VH2C",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997658907,
          "user_tz": -60,
          "elapsed": 37744,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "de6bad30b3654521b8625ffc2f2397bd",
            "429e1d9e9e6e4eff8a96a944a49394f0",
            "3c70ffe4c1194358b717d924635f6cac",
            "ac27b2b3ba314d1daacba9dfb3efc93a",
            "035afcb77a894f26944fe48ae59f8e9a",
            "e8836d25786444d4b7f0b6dca0ab4b07",
            "dc841270cb74493581382e274819a009",
            "1414063d79a14b2f81170a8ddfcc45fe",
            "6eee13f1cc1e4059a9a6f1c2e72dead7",
            "addc1466b9da44f8999435d422f5abc2",
            "4621ba75f58a422fb7eafd436b24b628",
            "4e80d50841b64ce6aff1b841e455fb32",
            "ce929b72593f4272b89267ec254cc16e",
            "4ab9ca43e7864749ae4101fb04c3f9db",
            "c13f1a1489ce486fa7f3b9c614075087",
            "b5c55eb72456447e821099471f1b8d02",
            "cd94d3b098654dc585adaabb45bf4d3c",
            "52e1ce10c6ee4a18bca2fbfd8a4a0447",
            "ba44a32439e24a1094f0d9a961936035",
            "df89a55a89c04b518f65f2b9cd8d79c2",
            "02c2c0cd45464e7883f53e9f6576b482",
            "7387ba14c2cd4d9782fa3b6c24a199c1",
            "e809d89184014459a546f814da3945fd",
            "e3136316534a4d129bfbafeb73cee946",
            "0a7932574675414ca39ef363128951ad",
            "7f71309b38bb4e529afd2d62216334a3",
            "ee3e4576090947c798249522fecac8bd",
            "ab5d6be292194d1caa12f7defe2ba208",
            "a0ca43a7744c4d09aa52e7f9d0c12c66",
            "551b6adcb5de45f59280a26fb711f0b4",
            "d631dc9ac73b4d92af45e7f1647dd0df",
            "6ba824acd6b64319868cebd66da97f19",
            "8443ff3516ab4b8da00d86392f24d71f",
            "19480c32028c40ddadae02039c3fc4ee",
            "cb4d3b5588b04a218c69004b09af45c0",
            "526896781acd47b39163ced42260a651",
            "373808b50b984f10b7d6f1b65dd7f040",
            "f4b48c35142b45a8a3c66b89fddbca64",
            "c9e6ca4616524798a4634179dfd3ea78",
            "6352d53afac24f9e9b2d407841b58b9d",
            "f79df8a89b314edf83fd19eba359c5f7",
            "3dcc9a4f5e02404b9b49ef8e0ce1701a",
            "cb32b1e870c94ba29c08ce52898bcd0d",
            "37fbbb7c368b4dc1bd5d49724f71ea7f",
            "5006b90f19ae46d8af909393fc613e98",
            "e6681414b145404e977a873dafedf8da",
            "0611fa665cf0499c86c160f0fbdf11d1",
            "f1d9261b718b4c1ab1a31d88b197b6a9",
            "ee12c21d255e457a910c4d1a450e3be4",
            "48287062ee70400bb6cb952fab8012b1",
            "c9ab538d4a9944f79da75bafd3ba170b",
            "87623d45a1194825bdf40eb03980d2d7",
            "fb783c1d6b964ee48befbfbbce6c2026",
            "0117f8f165f541aebbba5d7a883eeb9e",
            "40f659a224dd489981cec2f830a6a02b"
          ]
        },
        "outputId": "6e6ce9e8-d0c0-47dd-9ed7-a0a3bd6a8787"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/982 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de6bad30b3654521b8625ffc2f2397bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/117M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e80d50841b64ce6aff1b841e455fb32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e809d89184014459a546f814da3945fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Standardizing formats (num_proc=2):   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19480c32028c40ddadae02039c3fc4ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5006b90f19ae46d8af909393fc613e98"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    # Ensure correct template application\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "# Data Loading and Formatting\n",
        "dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")\n",
        "dataset = standardize_sharegpt(dataset)\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True, remove_columns=dataset.column_names)\n",
        "dataset = dataset.select(range(50000))\n",
        "\n",
        "# Create subset datasets for the two stages\n",
        "coarse_dataset = dataset.shuffle(seed=SEED).select(range(COARSE_DATASET_SIZE))\n",
        "fine_dataset = dataset.shuffle(seed=SEED).select(range(FINE_DATASET_SIZE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F97hxC5jAbrG"
      },
      "source": [
        "## Hyperparameter Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kbfImh7OV5zs",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997658927,
          "user_tz": -60,
          "elapsed": 16,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        }
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial, training_dataset, trial_stage: str):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Hyper-parameter space\n",
        "    r_value = trial.suggest_categorical(\"r\", [8, 16, 32])\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 4e-5, 4e-4, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 0.005, 0.05, log=True)\n",
        "\n",
        "    print(f\"\\n--- Starting Trial {trial.number} ({trial_stage} stage) ---\")\n",
        "    print(f\"Params: LR={learning_rate:.2e}, r={r_value}, weight_decay={weight_decay}, Data Size: {len(training_dataset)}\")\n",
        "\n",
        "    # 2. Model Setup\n",
        "    current_base_model, current_tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = BASE_MODEL_NAME,\n",
        "        max_seq_length = MAX_SEQ_LENGTH,\n",
        "        dtype = D_TYPE,\n",
        "        load_in_4bit = LOAD_IN_4BIT,\n",
        "    )\n",
        "    current_tokenizer = get_chat_template(current_tokenizer, chat_template=CHAT_TEMPLATE)\n",
        "\n",
        "\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        current_base_model,\n",
        "        r=r_value,\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "        lora_alpha=r_value,\n",
        "        lora_dropout=0,\n",
        "        bias=\"none\",\n",
        "        use_gradient_checkpointing=\"unsloth\",\n",
        "        random_state=SEED,\n",
        "    )\n",
        "\n",
        "    # 3. Training Arguments Setup\n",
        "    trial_output_dir = os.path.join(CHECKPOINT_DIR, f\"{trial_stage}_trial_{trial.number}\")\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=trial_output_dir,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=learning_rate,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=5,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=weight_decay,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=SEED,\n",
        "        report_to=\"none\",\n",
        "        save_strategy='no', # Only evaluating loss, no need to save\n",
        "    )\n",
        "\n",
        "    # 4. SFTTrainer Initialization and Training\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        tokenizer=current_tokenizer,\n",
        "        train_dataset=training_dataset,\n",
        "        eval_dataset=training_dataset,\n",
        "        dataset_text_field=\"text\",\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        data_collator=DataCollatorForSeq2Seq(tokenizer=current_tokenizer),\n",
        "        dataset_num_proc=6,\n",
        "        packing=False,\n",
        "        args=args,\n",
        "    )\n",
        "\n",
        "    trainer = train_on_responses_only(\n",
        "        trainer,\n",
        "        instruction_part=\"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "        response_part=\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # 5. Evaluation and Cleanup\n",
        "    final_eval_loss = trainer.evaluate()[\"eval_loss\"]\n",
        "\n",
        "    # Clean up memory\n",
        "    del model, current_base_model, trainer, current_tokenizer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return final_eval_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "### Coarse-grained Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YT3WVOVQWeDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997662891,
          "user_tz": -60,
          "elapsed": 3963,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "0dd2fb8e-50cd-4007-b2cf-6a6584c2d98f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-06 05:07:42,746] Using an existing study with name 'coarse-hyper-params' instead of creating a new one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STAGE 1: COARSE SEARCH (12/12 done)\n",
            "============================================================\n",
            "Coarse search already complete.\n"
          ]
        }
      ],
      "source": [
        "coarse_study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"coarse-hyper-params\",\n",
        "    storage=f\"sqlite:///{CHECKPOINT_DIR}/optuna_study.db\",\n",
        "    load_if_exists=True,\n",
        ")\n",
        "\n",
        "completed_coarse = [\n",
        "    t for t in coarse_study.trials\n",
        "    if t.state == optuna.trial.TrialState.COMPLETE\n",
        "]\n",
        "coarse_needed = COARSE_TRIALS - len(completed_coarse)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"STAGE 1: COARSE SEARCH ({len(completed_coarse)}/{COARSE_TRIALS} done)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if coarse_needed > 0:\n",
        "    coarse_study.optimize(\n",
        "        lambda trial: objective(trial, coarse_dataset, \"coarse\"),\n",
        "        n_trials=coarse_needed,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "else:\n",
        "    print(\"Coarse search already complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from plotly.io import show\n",
        "fig = optuna.visualization.plot_contour(coarse_study)\n",
        "show(fig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "vYzRy3Q-b_4z",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997665908,
          "user_tz": -60,
          "elapsed": 3016,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "2b71d7db-e8dc-41f3-f01b-73421e2eb000"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"20ad513d-1816-4b7b-9719-180efa8f8e35\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"20ad513d-1816-4b7b-9719-180efa8f8e35\")) {                    Plotly.newPlot(                        \"20ad513d-1816-4b7b-9719-180efa8f8e35\",                        [{\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":true,\"showscale\":true,\"x\":[0.00003971597464163447,0.00004417617869165683,0.00008473439869168232,0.00009292276583295462,0.00011481745303465972,0.00012779220516494422,0.0001546357022574806,0.00015922999286603704,0.0001852573275957084,0.0002475732755729107,0.0003014777506204959,0.00030569798329522797,0.00037123299712294377,0.0004129233983332898],\"y\":[6.8,8,16,32,33.2],\"z\":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,0.8094722628593445,null,null,null,null,0.7838287949562073,null,null,null],[null,null,0.8092156052589417,0.8066805005073547,null,null,null,null,0.7857256531715393,null,null,0.7689691185951233,0.7611892223358154,null],[null,0.8148012161254883,null,null,0.7859302759170532,null,0.776029109954834,0.7750181555747986,null,0.7576804757118225,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null]],\"type\":\"contour\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Gray\",\"width\":2.0}},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.00015922999286603704,0.0002475732755729107,0.00012779220516494422,0.00030569798329522797,0.00009292276583295462,0.00008473439869168232,0.00011481745303465972,0.0003014777506204959,0.0001852573275957084,0.0001546357022574806,0.00004417617869165683,0.00037123299712294377],\"y\":[32,32,8,16,16,16,32,8,16,32,32,16],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":true,\"showscale\":false,\"x\":[0.00003971597464163447,0.00004417617869165683,0.00008473439869168232,0.00009292276583295462,0.00011481745303465972,0.00012779220516494422,0.0001546357022574806,0.00015922999286603704,0.0001852573275957084,0.0002475732755729107,0.0003014777506204959,0.00030569798329522797,0.00037123299712294377,0.0004129233983332898],\"y\":[0.005370290943932947,0.005969371166689865,0.006932414832286732,0.007824288139795825,0.00959905935891669,0.01220700606020634,0.012847027487212599,0.016946784233875283,0.02308764866643218,0.023259286745731435,0.04599253263127407,0.048781473536841494,0.04949302009218528,0.05501419013889129],\"z\":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,0.7611892223358154,null],[null,null,null,null,null,null,null,null,null,null,null,0.7689691185951233,null,null],[null,null,null,null,null,null,null,null,null,null,0.7838287949562073,null,null,null],[null,null,null,0.8066805005073547,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,0.776029109954834,null,null,null,null,null,null,null],[null,null,null,null,0.7859302759170532,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,0.7576804757118225,null,null,null,null],[null,null,null,null,null,0.8094722628593445,null,null,null,null,null,null,null,null],[null,0.8148012161254883,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,0.7857256531715393,null,null,null,null,null],[null,null,0.8092156052589417,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,0.7750181555747986,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null]],\"type\":\"contour\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Gray\",\"width\":2.0}},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.00015922999286603704,0.0002475732755729107,0.00012779220516494422,0.00030569798329522797,0.00009292276583295462,0.00008473439869168232,0.00011481745303465972,0.0003014777506204959,0.0001852573275957084,0.0001546357022574806,0.00004417617869165683,0.00037123299712294377],\"y\":[0.04949302009218528,0.016946784233875283,0.02308764866643218,0.006932414832286732,0.00959905935891669,0.048781473536841494,0.012847027487212599,0.007824288139795825,0.04599253263127407,0.01220700606020634,0.023259286745731435,0.005969371166689865],\"type\":\"scatter\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":true,\"showscale\":false,\"x\":[6.8,8,16,32,33.2],\"y\":[0.00003971597464163447,0.00004417617869165683,0.00008473439869168232,0.00009292276583295462,0.00011481745303465972,0.00012779220516494422,0.0001546357022574806,0.00015922999286603704,0.0001852573275957084,0.0002475732755729107,0.0003014777506204959,0.00030569798329522797,0.00037123299712294377,0.0004129233983332898],\"z\":[[null,null,null,null,null],[null,null,null,0.8148012161254883,null],[null,null,0.8092156052589417,null,null],[null,null,0.8066805005073547,null,null],[null,null,null,0.7859302759170532,null],[null,0.8094722628593445,null,null,null],[null,null,null,0.776029109954834,null],[null,null,null,0.7750181555747986,null],[null,null,0.7857256531715393,null,null],[null,null,null,0.7576804757118225,null],[null,0.7838287949562073,null,null,null],[null,null,0.7689691185951233,null,null],[null,null,0.7611892223358154,null,null],[null,null,null,null,null]],\"type\":\"contour\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Gray\",\"width\":2.0}},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[32,32,8,16,16,16,32,8,16,32,32,16],\"y\":[0.00015922999286603704,0.0002475732755729107,0.00012779220516494422,0.00030569798329522797,0.00009292276583295462,0.00008473439869168232,0.00011481745303465972,0.0003014777506204959,0.0001852573275957084,0.0001546357022574806,0.00004417617869165683,0.00037123299712294377],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":true,\"showscale\":false,\"x\":[6.8,8,16,32,33.2],\"y\":[0.005370290943932947,0.005969371166689865,0.006932414832286732,0.007824288139795825,0.00959905935891669,0.01220700606020634,0.012847027487212599,0.016946784233875283,0.02308764866643218,0.023259286745731435,0.04599253263127407,0.048781473536841494,0.04949302009218528,0.05501419013889129],\"z\":[[null,null,null,null,null],[null,null,0.7611892223358154,null,null],[null,null,0.7689691185951233,null,null],[null,0.7838287949562073,null,null,null],[null,null,0.8066805005073547,null,null],[null,null,null,0.776029109954834,null],[null,null,null,0.7859302759170532,null],[null,null,null,0.7576804757118225,null],[null,0.8094722628593445,null,null,null],[null,null,null,0.8148012161254883,null],[null,null,0.7857256531715393,null,null],[null,null,0.8092156052589417,null,null],[null,null,null,0.7750181555747986,null],[null,null,null,null,null]],\"type\":\"contour\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Gray\",\"width\":2.0}},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[32,32,8,16,16,16,32,8,16,32,32,16],\"y\":[0.04949302009218528,0.016946784233875283,0.02308764866643218,0.006932414832286732,0.00959905935891669,0.048781473536841494,0.012847027487212599,0.007824288139795825,0.04599253263127407,0.01220700606020634,0.023259286745731435,0.005969371166689865],\"type\":\"scatter\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":true,\"showscale\":false,\"x\":[0.005370290943932947,0.005969371166689865,0.006932414832286732,0.007824288139795825,0.00959905935891669,0.01220700606020634,0.012847027487212599,0.016946784233875283,0.02308764866643218,0.023259286745731435,0.04599253263127407,0.048781473536841494,0.04949302009218528,0.05501419013889129],\"y\":[0.00003971597464163447,0.00004417617869165683,0.00008473439869168232,0.00009292276583295462,0.00011481745303465972,0.00012779220516494422,0.0001546357022574806,0.00015922999286603704,0.0001852573275957084,0.0002475732755729107,0.0003014777506204959,0.00030569798329522797,0.00037123299712294377,0.0004129233983332898],\"z\":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,0.8148012161254883,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.8092156052589417,null,null],[null,null,null,null,0.8066805005073547,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,0.7859302759170532,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,0.8094722628593445,null,null,null,null,null],[null,null,null,null,null,0.776029109954834,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,0.7750181555747986,null],[null,null,null,null,null,null,null,null,null,null,0.7857256531715393,null,null,null],[null,null,null,null,null,null,null,0.7576804757118225,null,null,null,null,null,null],[null,null,null,0.7838287949562073,null,null,null,null,null,null,null,null,null,null],[null,null,0.7689691185951233,null,null,null,null,null,null,null,null,null,null,null],[null,0.7611892223358154,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null]],\"type\":\"contour\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Gray\",\"width\":2.0}},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.04949302009218528,0.016946784233875283,0.02308764866643218,0.006932414832286732,0.00959905935891669,0.048781473536841494,0.012847027487212599,0.007824288139795825,0.04599253263127407,0.01220700606020634,0.023259286745731435,0.005969371166689865],\"y\":[0.00015922999286603704,0.0002475732755729107,0.00012779220516494422,0.00030569798329522797,0.00009292276583295462,0.00008473439869168232,0.00011481745303465972,0.0003014777506204959,0.0001852573275957084,0.0001546357022574806,0.00004417617869165683,0.00037123299712294377],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":true,\"showscale\":false,\"x\":[0.005370290943932947,0.005969371166689865,0.006932414832286732,0.007824288139795825,0.00959905935891669,0.01220700606020634,0.012847027487212599,0.016946784233875283,0.02308764866643218,0.023259286745731435,0.04599253263127407,0.048781473536841494,0.04949302009218528,0.05501419013889129],\"y\":[6.8,8,16,32,33.2],\"z\":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,0.7838287949562073,null,null,null,null,0.8094722628593445,null,null,null,null,null],[null,0.7611892223358154,0.7689691185951233,null,0.8066805005073547,null,null,null,null,null,0.7857256531715393,0.8092156052589417,null,null],[null,null,null,null,null,0.776029109954834,0.7859302759170532,0.7576804757118225,null,0.8148012161254883,null,null,0.7750181555747986,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null]],\"type\":\"contour\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Gray\",\"width\":2.0}},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.04949302009218528,0.016946784233875283,0.02308764866643218,0.006932414832286732,0.00959905935891669,0.048781473536841494,0.012847027487212599,0.007824288139795825,0.04599253263127407,0.01220700606020634,0.023259286745731435,0.005969371166689865],\"y\":[32,32,8,16,16,16,32,8,16,32,32,16],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"type\":\"scatter\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2888888888888889],\"matches\":\"x7\",\"showticklabels\":false,\"range\":[-4.401034775270201,-3.3841305071007897],\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.7333333333333333,1.0],\"range\":[-4.401034775270201,-3.3841305071007897],\"type\":\"log\",\"title\":{\"text\":\"learning_rate\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.35555555555555557,0.6444444444444445],\"matches\":\"x8\",\"showticklabels\":false,\"range\":[6.8,33.2]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.7333333333333333,1.0],\"matches\":\"y\",\"showticklabels\":false,\"range\":[-4.401034775270201,-3.3841305071007897],\"type\":\"log\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.7111111111111111,1.0],\"matches\":\"x9\",\"showticklabels\":false,\"range\":[-2.2700021850785057,-1.259525275884689],\"type\":\"log\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.7333333333333333,1.0],\"matches\":\"y\",\"showticklabels\":false,\"range\":[-4.401034775270201,-3.3841305071007897],\"type\":\"log\"},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.0,0.2888888888888889],\"matches\":\"x7\",\"showticklabels\":false,\"range\":[-4.401034775270201,-3.3841305071007897],\"type\":\"log\"},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.36666666666666664,0.6333333333333333],\"range\":[6.8,33.2],\"title\":{\"text\":\"r\"}},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.35555555555555557,0.6444444444444445],\"matches\":\"x8\",\"showticklabels\":false,\"range\":[6.8,33.2]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.36666666666666664,0.6333333333333333],\"matches\":\"y4\",\"showticklabels\":false,\"range\":[6.8,33.2]},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.7111111111111111,1.0],\"matches\":\"x9\",\"showticklabels\":false,\"range\":[-2.2700021850785057,-1.259525275884689],\"type\":\"log\"},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.36666666666666664,0.6333333333333333],\"matches\":\"y4\",\"showticklabels\":false,\"range\":[6.8,33.2]},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.0,0.2888888888888889],\"range\":[-4.401034775270201,-3.3841305071007897],\"type\":\"log\",\"title\":{\"text\":\"learning_rate\"}},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,0.26666666666666666],\"range\":[-2.2700021850785057,-1.259525275884689],\"type\":\"log\",\"title\":{\"text\":\"weight_decay\"}},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.35555555555555557,0.6444444444444445],\"range\":[6.8,33.2],\"title\":{\"text\":\"r\"}},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,0.26666666666666666],\"matches\":\"y7\",\"showticklabels\":false,\"range\":[-2.2700021850785057,-1.259525275884689],\"type\":\"log\"},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.7111111111111111,1.0],\"range\":[-2.2700021850785057,-1.259525275884689],\"type\":\"log\",\"title\":{\"text\":\"weight_decay\"}},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.0,0.26666666666666666],\"matches\":\"y7\",\"showticklabels\":false,\"range\":[-2.2700021850785057,-1.259525275884689],\"type\":\"log\"},\"title\":{\"text\":\"Contour Plot\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('20ad513d-1816-4b7b-9719-180efa8f8e35');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = optuna.visualization.plot_param_importances(coarse_study)\n",
        "show(fig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "SV5v-6UFdGGn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997666129,
          "user_tz": -60,
          "elapsed": 220,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "6afea91c-0db3-4cc5-ad81-2cd0b5e2db7d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"908e6bc0-a5c7-4cfd-9b5e-1f8d1975f052\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"908e6bc0-a5c7-4cfd-9b5e-1f8d1975f052\")) {                    Plotly.newPlot(                        \"908e6bc0-a5c7-4cfd-9b5e-1f8d1975f052\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"r (CategoricalDistribution): 0.09280608975132579\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"weight_decay (FloatDistribution): 0.0950789168688249\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.8121149933798493\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"0.09\",\"0.10\",\"0.81\"],\"textposition\":\"outside\",\"x\":[0.09280608975132579,0.0950789168688249,0.8121149933798493],\"y\":[\"r\",\"weight_decay\",\"learning_rate\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('908e6bc0-a5c7-4cfd-9b5e-1f8d1975f052');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-ZFFvisAzDE"
      },
      "source": [
        "### Fine-grained Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fbOmqeNrWtjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997666277,
          "user_tz": -60,
          "elapsed": 137,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "e17f55d5-de07-4dab-d3df-dda79468ef93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-06 05:07:46,083] Using an existing study with name 'fine-hyper-params' instead of creating a new one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STAGE 2: FINE SEARCH (Top 4 Coarse Candidates)\n",
            "============================================================\n",
            "Skipping Fine Tune for Coarse Trial #1 (Already Complete)\n",
            "Skipping Fine Tune for Coarse Trial #12 (Already Complete)\n",
            "Skipping Fine Tune for Coarse Trial #3 (Already Complete)\n",
            "Skipping Fine Tune for Coarse Trial #0 (Already Complete)\n",
            "\n",
            "ðŸ† Best Result:\n",
            "Loss: 0.7303\n",
            "Params: {'r': 32, 'learning_rate': 0.0002475732755729107, 'weight_decay': 0.016946784233875283}\n"
          ]
        }
      ],
      "source": [
        "fine_study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    study_name=\"fine-hyper-params\",\n",
        "    storage=f\"sqlite:///{CHECKPOINT_DIR}/optuna_study.db\",\n",
        "    load_if_exists=True,\n",
        ")\n",
        "\n",
        "coarse_trials = coarse_study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.COMPLETE])\n",
        "best_coarse_trials = sorted(coarse_trials, key=lambda t: t.value)[:FINE_TRIALS]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"STAGE 2: FINE SEARCH (Top {len(best_coarse_trials)} Coarse Candidates)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 2. Iterate through best candidates and run them ONE BY ONE if missing\n",
        "for coarse_trial in best_coarse_trials:\n",
        "\n",
        "    # Check if a COMPLETED fine trial already exists for this specific coarse_trial ID\n",
        "    already_done = False\n",
        "    for t in fine_study.trials:\n",
        "        if (t.state == optuna.trial.TrialState.COMPLETE\n",
        "            and t.user_attrs.get(\"source_coarse_id\") == coarse_trial.number):\n",
        "            already_done = True\n",
        "            break\n",
        "\n",
        "    if already_done:\n",
        "        print(f\"Skipping Fine Tune for Coarse Trial #{coarse_trial.number} (Already Complete)\")\n",
        "        continue\n",
        "\n",
        "    # If we are here, we need to run this specific trial\n",
        "    print(f\"Running Fine Tune for Coarse Trial #{coarse_trial.number}...\")\n",
        "\n",
        "    # Enqueue the parameters\n",
        "    fine_study.enqueue_trial(\n",
        "        params=coarse_trial.params,\n",
        "        user_attrs={\n",
        "            \"source_coarse_id\": coarse_trial.number\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Run exactly ONE trial to process the queue item we just added\n",
        "    fine_study.optimize(\n",
        "        lambda trial: objective(trial, fine_dataset, \"fine\"),\n",
        "        n_trials=1,\n",
        "        show_progress_bar=False\n",
        "    )\n",
        "\n",
        "# Final Results\n",
        "fine_trials = [\n",
        "    t for t in fine_study.trials\n",
        "    if t.state == optuna.trial.TrialState.COMPLETE\n",
        "]\n",
        "\n",
        "if fine_trials:\n",
        "    best_fine = min(fine_trials, key=lambda t: t.value)\n",
        "    print(\"\\nðŸ† Best Result:\")\n",
        "    print(f\"Loss: {best_fine.value:.4f}\")\n",
        "    print(f\"Params: {best_fine.params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA4Fpc7XaC3a"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402,
          "referenced_widgets": [
            "3e9cfb58c7da4328a7d9128d2e4ab4cb",
            "279c7ea8bf4b4a50a0a15414dd3815c8",
            "adbffa4e7617462cb7327028953c6115",
            "d9f9bc06a0f74925acf4b9a497880e64",
            "6fb3dccfc9314790975b417ed256b43b",
            "5b87ba8dc0e843cf942b42c6eb119d9b",
            "9eae1aea5596459a982e9f625169565c",
            "73e2f52a14bb4b43adddd7fa80ca03bd",
            "1e6b2a1b6b1046b1a6f0a63a991b3088",
            "0e2c2b7544eb4dcd8039f3924a40da99",
            "5ee7ed70f65044a993735081baa33266",
            "f56a79f9defe4089a47fd6193a7b911d",
            "f389d467cc184426aa2d6ab0b3300a9e",
            "819c9088eabf40e5a822b333f75ddc29",
            "a3ab1c38d9684300bf979ba514118b4a",
            "aff536f54d1c4394b0791cd44af49f6a",
            "054d50d44bbe4fd9826cde7968c9e2df",
            "1e0160e1e9e04ce8a391c1c9ef8ea88c",
            "8e67948dde7a4510ab232fd70e60c4dc",
            "4fdecaef886842bc8c3b41ccc53ad3f7",
            "95e3941a99be4eb6935fbdaaaccd7a5d",
            "c1748e8d012c4e16856ad258760540cb"
          ]
        },
        "id": "95_Nn-89DhsL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997836058,
          "user_tz": -60,
          "elapsed": 169234,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "3bb5571a-1f5d-4a75-fd1a-3eea27e7ce66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.11.6: Fast Llama patching. Transformers: 4.57.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.11.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e9cfb58c7da4328a7d9128d2e4ab4cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=6):   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f56a79f9defe4089a47fd6193a7b911d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming from: /content/drive/MyDrive/unsloth/Llama-3.2-3B-Instruct-bnb-4bit/checkpoint-1563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 50,000 | Num Epochs = 1 | Total steps = 1,563\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
            " \"-____-\"     Trainable parameters = 48,627,712 of 3,261,377,536 (1.49% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1563/1563 : < :, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from unsloth.chat_templates import train_on_responses_only\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "r_value = best_fine.params[\"r\"]\n",
        "weight_decay = best_fine.params[\"weight_decay\"]\n",
        "learning_rate = best_fine.params[\"learning_rate\"]\n",
        "\n",
        "current_base_model, current_tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = BASE_MODEL_NAME,\n",
        "    max_seq_length = MAX_SEQ_LENGTH,\n",
        "    dtype = D_TYPE,\n",
        "    load_in_4bit = LOAD_IN_4BIT,\n",
        ")\n",
        "current_tokenizer = get_chat_template(current_tokenizer, chat_template=CHAT_TEMPLATE)\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    current_base_model,\n",
        "    r=r_value,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=r_value,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=SEED,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    eval_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
        "    dataset_num_proc=10,\n",
        "    packing=False,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        learning_rate=learning_rate,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=20,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=weight_decay,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=SEED,\n",
        "        num_train_epochs=1,\n",
        "        save_strategy='steps',\n",
        "        save_steps=100,\n",
        "        save_total_limit=3,\n",
        "        output_dir=CHECKPOINT_DIR,\n",
        "        gradient_checkpointing=True,\n",
        "        report_to=None,\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")\n",
        "\n",
        "checkpoints = [f for f in os.listdir(CHECKPOINT_DIR) if f.startswith('checkpoint')]\n",
        "checkpoints.sort(key=lambda x: int(x.split('-')[-1]))\n",
        "if checkpoints:\n",
        "    latest_checkpoint = os.path.join(CHECKPOINT_DIR, checkpoints[-1])\n",
        "    print('Resuming from:', latest_checkpoint)\n",
        "else:\n",
        "    latest_checkpoint = None\n",
        "    print('No checkpoint found. Starting fresh.')\n",
        "trainer_stats = trainer.train(resume_from_checkpoint=latest_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2ejIt2xSNKKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997836075,
          "user_tz": -60,
          "elapsed": 15,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "8b719c51-6528-4f9f-dac2-0dbf01b6c98f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "5.184 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pCqnaKmlO1U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997836081,
          "user_tz": -60,
          "elapsed": 5,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "ea2787a6-533e-4b96-c335-477d41cccfb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0295 seconds used for training.\n",
            "0.0 minutes used for training.\n",
            "Peak reserved memory = 5.184 GB.\n",
            "Peak reserved memory for training = 0.0 GB.\n",
            "Peak reserved memory % of max memory = 35.167 %.\n",
            "Peak reserved memory for training % of max memory = 0.0 %.\n"
          ]
        }
      ],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original prompts, expected answer, modified prompt\n",
        "prompts = [\n",
        "    (\n",
        "        \"Discuss the efforts of the United Nations to advance world peace.\",\n",
        "        \"The United Nations is a global organization with a mission to promote international peace and security. Since its founding in 1945, the United Nations has been a major force in global diplomacy, working to resolve conflicts both on a regional and international level. The United Nations has organized peacekeeping missions and negotiated ceasefires, arms embargoes and disarmament agreements in countries around the world. The United Nations also works to provide humanitarian and economic assistance to areas affected by war, famine, and natural disasters. The United Nations also seeks to promote human rights and gender equality, uphold international law and advocate for global economic and social justice. By providing a forum for dialogue and discussion between member states, the United Nations seeks to advance dialogue and constructively address issues that have the potential to lead to conflict and war.\",\n",
        "        \"Describe the United Nationsâ€™ efforts aimed at promoting global peace.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Why is a wing necessary for flight, given that an engine can provide the necessary energy to counter gravity and propel an airplane forward?\",\n",
        "        \"The wing serves a crucial role in flight efficiency by converting the engine's horizontal energy into vertical lift without significantly increasing the overall energy expenditure. While tilting the engine downward could create lift, it would also cause a significant loss in forward thrust due to the conservation of energy and momentum.\\n\\nTo understand this better, consider the trade-off between momentum and energy. The wing generates lift by moving a large volume of air a small distance (or a small volume of air a large distance), which results in lower kinetic energy transfer to the air. This is more energy-efficient than directly tilting the engine, which would create a smaller volume of air moving at a higher velocity, dissipating more energy as noise and heat.\\n\\nAdditionally, the wing's shape and size enable it to optimize this trade-off, with long, thin wings being particularly efficient at generating lift with minimal energy loss. In contrast, using the engine alone to produce both lift and thrust would be less efficient, as it would require a significant amount of energy to compress air, mix it with fuel, and accelerate the resulting gases, all of which contribute to energy wastage.\\n\\nIn essence, the wing acts as a mediator that redirects the engine's energy into both horizontal thrust and vertical lift, ensuring a more efficient flight experience. This is why wings are essential in aircraft design, even when engines can provide the necessary energy for lift and propulsion.\",\n",
        "        \"Why are wings essential for flight if engines can provide necessary energy for countering gravity and thrusting the plane forward?\"\n",
        "    ),\n",
        "    (\n",
        "        \"How can I plot a circle with matplotlib.pyplot in Python, taking as input center (x,y) and radius r? I attempted several variations similar to the code below but have not been successful. Here is the code I tried:\\n\\n```python\\nimport matplotlib.pyplot as plt\\ncircle=plt.Circle((0,0),2)\\n# here must be something like circle.plot() or not?\\nplt.show()\\n```\\nI am specifically looking for a solution that does not involve the use of pylab.\",\n",
        "        \"The circle object that you created using `plt.Circle` is a patch, and must be added to the current axes using the `add_patch` method. The following code shows how this can be done:\\n\\n```python\\nimport matplotlib.pyplot as plt\\n\\nfig, ax = plt.subplots() # note we must use plt.subplots, not plt.subplot\\n# (or if you have an existing figure)\\n# fig = plt.gcf()\\n# ax = fig.gca()\\n\\ncircle = plt.Circle((0, 0), 2, fill = False)\\n\\nax.add_patch(circle)\\n\\n# Set the limits of the plot to be equal, so the circle isn't distorted\\nax.axis('equal')\\n\\nplt.show()\\n```\\n\\nIn the above code:\\n- `plt.subplots()` is used to create a new figure and a set of subplots.\\n- `plt.Circle((0, 0), 2, fill = False)` creates a circle centered at (0, 0) with radius 2. `fill = False` makes the circle empty. If you want a filled circle, you can omit this parameter or set it to `True`.\\n- `ax.add_patch(circle)` adds the circle to the axes.\\n- `ax.axis('equal')` sets the aspect of the plot box to 'equal'. The aspect is the ratio of the y-unit to the x-unit and by setting it to 'equal', the units on the x and y axes are the same, ensuring that the circle is not distorted.\",\n",
        "        \"How can I draw a circle in matplotlib using only its center (x, y) and radius r? Several similar variants to the attempt below have not been successful. This is my code:```python\\nimport matplotlib.pyplot as plt\\ncircle=plt.Circle((1,0),5)\\n# Something like circle.plot() here?\\nplt.show()\\n```\\nI am not looking for an implementation that uses pylab.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Discuss two practical and cost-effective ways to help the environment, one of which must involve implementing renewable energy sources, while the other must include reducing carbon emissions from transportation, and explain how these solutions can be implemented in developing countries with limited resources. Additionally, provide a comparative analysis of the benefits and drawbacks of these solutions in terms of their impact on economic growth, social equity, and environmental sustainability. Finally, outline a comprehensive action plan for governments, NGOs, and individuals to promote these solutions at the local, national, and international levels, taking into account the cultural, political, and technological factors that may affect their success. Consider providing case studies or real-life examples to illustrate the potential of these solutions and inspire others to take action.\",\n",
        "        \"Solution 1: Implementing Renewable Energy Sources\\nOne practical and cost-effective way to help the environment is to implement renewable energy sources. Renewable energy sources such as solar, wind, and hydroelectric power can be harnessed to generate electricity without emitting harmful greenhouse gases. This can help reduce carbon emissions and mitigate the impact of climate change.\\nIn developing countries with limited resources, implementing renewable energy sources can be challenging due to the high cost of technology and infrastructure. However, there are several ways to overcome these challenges. One approach is to promote decentralized renewable energy systems that can be installed in remote areas without access to the main power grid. This can be done through microfinance schemes that provide loans to households and small businesses to purchase renewable energy systems.\\nAnother approach is to promote public-private partnerships that can help mobilize resources and expertise to develop renewable energy projects. Governments can provide incentives such as tax breaks and subsidies to attract private sector investment in renewable energy projects. NGOs can also play a role in promoting renewable energy by providing technical assistance and capacity building to local communities.\\nIn terms of economic growth, implementing renewable energy sources can create new job opportunities and stimulate economic development. However, there may be initial costs associated with building the necessary infrastructure, which could be a challenge for countries with limited resources. Additionally, there may be social equity concerns if the benefits of renewable energy are not distributed evenly among different groups.\\nSolution 2: Reducing Carbon Emissions from Transportation\\nAnother practical and cost-effective way to help the environment is to reduce carbon emissions from transportation. This can be done by promoting the use of public transportation, encouraging the adoption of electric vehicles, and promoting non-motorized transportation such as walking and cycling.\\nIn developing countries with limited resources, reducing carbon emissions from transportation can be challenging due to the lack of infrastructure and resources. However, there are several ways to overcome these challenges. One approach is to promote the use of public transportation by investing in bus rapid transit systems and promoting the use of shared transportation services such as carpooling and bike-sharing.\\nAnother approach is to promote the adoption of electric vehicles by providing incentives such as tax breaks and subsidies to encourage their purchase. Governments can also invest in charging infrastructure to support the adoption of electric vehicles.\\nIn terms of economic growth, reducing carbon emissions from transportation can create new job opportunities in the renewable energy and transportation sectors. However, there may be initial costs associated with building the necessary infrastructure, which could be a challenge for countries with limited resources. Additionally, there may be social equity concerns if the benefits of reduced carbon emissions are not distributed evenly among different groups.\\nComprehensive Action Plan\\nTo promote these solutions at the local, national, and international levels, governments, NGOs, and individuals can take the following actions:\\n1. Raise awareness: Governments and NGOs can launch awareness campaigns to educate the public about the benefits of renewable energy and reducing carbon emissions from transportation.\\n2. Provide incentives: Governments can provide tax breaks, subsidies, and other incentives to promote the adoption of renewable energy and electric vehicles.\\n3. Build infrastructure: Governments can invest in the necessary infrastructure to support renewable energy and public transportation systems.\\n4. Promote public-private partnerships: Governments can work with the private sector to mobilize resources and expertise to develop renewable energy projects and promote sustainable transportation.\\n5. Encourage behavior change: Individuals can be encouraged to adopt sustainable transportation habits such as walking, cycling, and carpooling.\\n6. Support research and development: Governments and NGOs can invest in research and development to improve the efficiency and affordability of renewable energy and sustainable transportation technologies.\\nCase Study: India\\nIndia is a developing country that has implemented several initiatives to promote renewable energy and sustainable transportation. The government has set a target of achieving 175 GW of renewable energy capacity by 2022, which includes 100 GW of solar power. The government has also launched several initiatives to promote electric vehicles, including tax breaks and subsidies for their purchase. Additionally, the government has invested in public transportation infrastructure, including the development of bus rapid transit systems in major cities.\\nConclusion\\nImplementing renewable energy sources and reducing carbon emissions from transportation are two practical and cost-effective ways to help the environment. These solutions can be implemented in developing countries with limited resources through a combination of public-private partnerships, incentives, and infrastructure development. While there may be initial costs associated with these solutions, they can stimulate economic growth, promote social equity, and contribute to environmental sustainability. Governments, NGOs, and individuals can take a comprehensive approach to promote these solutions at the local, national, and international levels, taking into account the cultural, political, and technological factors that may affect their success.\",\n",
        "        \"Examine two practical and affordable strategies for environmental protectionâ€”one focusing on implementing renewable energy technologies, and the other targeting the reduction of carbon emissions from transportation. Detail how these approaches can be applied in resource-constrained developing nations. Furthermore, offer a comparative analysis of their advantages and disadvantages regarding economic growth, social fairness, and ecological sustainability. Conclude by proposing a detailed action plan for governments, NGOs, and individuals to advance these initiatives across local, national, and global arenas, while accounting for cultural, political, and technological variables that could influence their success. Where possible, include case studies or real-life examples to demonstrate the potential of these methods and motivate others to make a difference.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Explain the chain of events leading to the signing of the Magna Carta in 1215.\",\n",
        "        \"1. King John's rule: King John of England faced numerous problems, including failed military campaigns, high taxation, and conflicts with the Pope.2. Barons' discontent: English barons were dissatisfied with King John's rule due to heavy taxes, loss of influence, and disregard for their rights and privileges.3. Tensions escalate: In 1215, rebel barons captured London, effectively forcing King John into negotiations.4. Magna Carta negotiations: Barons presented King John with a document outlining their demands, which aimed to limit the king's power by protecting their rights and ensuring fair treatment.5. Signing of the Magna Carta: On June 15, 1215, King John signed the Magna Carta at Runnymede, ultimately symbolizing the first significant step towards limiting the power of the monarchy and establishing the foundation for future democratic principles.\",\n",
        "        \"Outline the sequence of events that led to the creation of the Magna Carta in 1215.\"\n",
        "    ),\n",
        "    (\n",
        "        \"How is stellar parallax measured?\",\n",
        "        \"Stellar parallax is measured by observing the apparent shift in the position of a star as seen from two different points on Earth's orbit around the Sun. This shift is caused by the change in the angle at which the star is viewed from these two points. The distance to the star can then be calculated using trigonometry.\\n\\nThe distance to a star is measured in parsecs. One parsec is equal to 3.26 light-years. The parallax angle is measured in arcseconds. One arcsecond is equal to 1/3600 of a degree.\\n\\nThe parallax angle is very small, even for the nearest stars. The parallax angle of the nearest star, Alpha Centauri, is only 0.772 arcseconds. This means that Alpha Centauri is about 4.3 light-years away from Earth.\\n\\nStellar parallax is a very important tool for astronomers. It allows them to measure the distances to stars and other objects in space. This information is essential for understanding the structure and evolution of the universe.\",\n",
        "        \"How does one measure stellar parallax?\"\n",
        "    ),\n",
        "    (\n",
        "        \"What is bacterial transformation, and how does it occur?\",\n",
        "        \"Bacterial transformation is a genetic modification process where bacteria take up external DNA from their environment and incorporate it into their own genome. This can result in the acquisition of new traits or characteristics.\\n\\nHere's a step-by-step explanation:\\n1. **DNA Preparation**: The gene or genetic material of interest is extracted from its original source and cut using a specific restriction enzyme.\\n2. **Plasmid Incorporation**: This DNA fragment is then inserted into a plasmid, a small, circular DNA molecule that is separate from the bacterial chromosome and can replicate independently.\\n3. **Ligation**: The plasmid with the inserted DNA is ligated, or joined together, to create a recombinant plasmid.\\n4. **Transformation**: The recombinant plasmid is introduced into bacteria, often using a laboratory procedure to facilitate uptake. Naturally transformable bacteria can also take up DNA spontaneously under certain environmental conditions.\\n5. **Integration**: Once inside the bacterial cell, the plasmid with the foreign DNA integrates into the bacterial chromosome or remains extrachromosomal, and the new genetic information is expressed.\\n\\nThis process is widely used in molecular biology for gene cloning and genetic engineering applications.\",\n",
        "        \"What is bacterial transformation, and through what process does it take place?\"\n",
        "    ),\n",
        "    (\n",
        "        \"What triggers the release of neurotransmitters?\",\n",
        "        \"The axon is a long, thin projection that extends from the cell body of a neuron. It is responsible for transmitting electrical signals away from the cell body. When an electrical signal reaches the end of the axon, it triggers the release of neurotransmitters into the synaptic cleft, the space between two neurons.\\n\\nNeurotransmitters are chemical messengers that allow neurons to communicate with each other. They are stored in small vesicles at the end of the axon. When an electrical signal reaches the end of the axon, it causes the vesicles to fuse with the cell membrane and release their neurotransmitters into the synaptic cleft.\\n\\nThe neurotransmitters then diffuse across the synaptic cleft and bind to receptors on the dendrites of the postsynaptic neuron. This binding triggers a new electrical signal in the postsynaptic neuron, which can then be transmitted to other neurons.\\n\\nThe release of neurotransmitters is a critical step in the process of neural communication. It allows neurons to send signals to each other and to control a wide range of bodily functions, including movement, thought, and emotion.\\n####\\nNeurotransmitters are released at the presynaptic terminal in response to a threshold action potential or graded electrical potential.\",\n",
        "        \"What causes neurons to release neurotransmitters?\"\n",
        "    ),\n",
        "    (\n",
        "        \"How does a processor execute an assembly instruction, like \\\"ADD 1,2,\\\" and produce an output, in the context of mapping a high-level block diagram to a circuit diagram?\",\n",
        "        \"To understand how a processor performs the addition of two numbers, such as 1 and 2, at a lower level, you need to delve into the underlying architecture and operations. Here's a simplified overview:\\n\\n1. **Language Abstraction**: You're familiar with high-level programming languages, but assembly language is one step lower. It directly corresponds to specific machine instructions, like \\\"ADD 1,2,\\\" which tells the processor to add the numbers stored at memory addresses 1 and 2.\\n\\n2. **Processor Components**: A processor contains functional units, like the arithmetic logic unit (ALU), which performs arithmetic operations. The control unit manages the flow of data and instruction execution.\\n\\n3. **æ•°å­—è¡¨ç¤º**: In a computer, numbers are typically represented in 2's complement notation. So, 1 and 2 would be binary numbers, and their sum would involve binary addition.\\n\\n4. **Circuit-Level Operations**: At the circuit level, an ALU is built using logic gates (such as AND, OR, and NOT gates) that implement the addition operation. A \\\"Full Adder\\\" circuit is used for this purpose, handling carry-in and carry-out for binary digits.\\n\\n5. **Execution**: When the \\\"ADD 1,2\\\" instruction is executed, the processor fetches the numbers from memory, loads them into registers, and sends them to the ALU. The ALU performs the binary addition, generates the sum (3 in this case), and stores it back in a register or memory.\\n\\nFor a deeper understanding, consider resources on digital electronics, particularly CMOS logic and binary arithmetic. A recommended course for beginners is the Georgia Tech ECE2030 class, which provides an introduction to computer engineering, though the course materials might be more detailed than what you're seeking.\\n\\nRemember, understanding this process requires a willingness to learn about the layers of abstraction beneath the software level. Good luck on your journey!\",\n",
        "        \"How does a processor turn an assembly instruction like \\\"ADD 1,2\\\" into an actual hardware-level operation and produce an output?\"\n",
        "    ),\n",
        "    (\n",
        "        \"How do protons overcome their repulsion and come close enough to form a nucleus, considering the short range of nuclear forces?\",\n",
        "        \"When protons are initially far apart, they possess sufficient kinetic energy to approach each other despite the electrostatic repulsion between them. As they get closer, they can experience a quantum mechanical phenomenon called tunneling, which allows them to pass through the energy barrier that would normally keep them apart due to their repulsion. Once they tunnel through this barrier, the strong nuclear force becomes significant, and the protons can be held together within a nucleus.\\n\\nIn some cases, this results in a temporary diproton nucleus, which is unstable. A process called beta decay occurs, where one of the protons converts into a neutron, forming a stable deuterium nucleus (deuteron). This deuteron can then participate in further nuclear fusion reactions, like those that power the sun.\",\n",
        "        \"How do protons manage to overcome their mutual repulsion and get close enough to make a nucleus, given the nuclear forceâ€™s short range?\"\n",
        "    ),\n",
        "    (\n",
        "        \"Develop an all-encompassing strategy that takes into account various factors such as economic, social, and environmental impacts to encourage the adoption of sustainable agricultural methods in densely populated urban regions. Additionally, devise ways to guarantee food availability and affordability for low-income neighborhoods while addressing the potential challenges that may arise in implementing such a plan.\",\n",
        "        \"To encourage the adoption of sustainable agricultural methods in densely populated urban regions, we need to consider economic, social, and environmental factors. Here is an all-encompassing strategy that can help:\\n1. Provide education and training: Educate farmers and urban residents about sustainable agricultural practices, such as organic farming, permaculture, and hydroponics. Train them on how to use these methods effectively to increase yields and reduce costs.\\n2. Create incentives: Offer tax incentives, subsidies, and grants to farmers who adopt sustainable practices. This will encourage more farmers to switch to sustainable methods and help offset the costs of transitioning.\\n3. Promote community gardens: Encourage the establishment of community gardens in urban areas. These gardens can provide fresh produce to low-income neighborhoods and promote social cohesion.\\n4. Partner with local businesses: Partner with local businesses to create a market for sustainable produce. This can help ensure that farmers have a reliable source of income and that consumers have access to fresh, healthy food.\\n5. Address food waste: Develop programs to reduce food waste by promoting composting and recycling. This can help reduce the environmental impact of agriculture and provide a source of fertilizer for sustainable farming practices.\\n6. Address food deserts: Work to ensure that low-income neighborhoods have access to fresh, healthy food. This can be done by promoting farmers' markets, community gardens, and other initiatives that increase access to fresh produce.\\n7. Address transportation issues: Develop transportation networks to ensure that produce can be transported from rural areas to urban areas quickly and efficiently. This can help reduce the environmental impact of transportation and ensure that produce remains fresh and affordable.\\n8. Address water scarcity: Develop water conservation programs to ensure that sustainable agriculture practices are not hindered by water scarcity. This can include rainwater harvesting, drip irrigation, and other water conservation methods.\\n9. Address energy needs: Develop renewable energy programs to power sustainable agriculture practices. This can include solar and wind power, as well as other renewable energy sources.\\n10. Address land use: Develop zoning laws and land use policies that encourage sustainable agriculture practices. This can include urban agriculture zoning, land trusts, and other policies that promote sustainable land use.\\nIn implementing this plan, we need to address potential challenges such as resistance from farmers, lack of funding, and limited resources. To guarantee food availability and affordability for low-income neighborhoods, we need to ensure that sustainable agriculture practices are economically viable and that produce is accessible to all. This can be done by partnering with local businesses, developing transportation networks, and addressing food deserts. By taking a holistic approach that addresses economic, social, and environmental factors, we can encourage the adoption of sustainable agriculture practices in densely populated urban regions.\",\n",
        "        \"Create a comprehensive strategy that considers economic, social, and environmental impacts to promote sustainable agriculture in highly populated urban areas. Also, design strategies to ensure food accessibility and affordability in low-income communities, while tackling the potential obstacles that could emerge during the planâ€™s implementation.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Discuss the origin and evolution of circuses, touching on significant milestones and changes in the types of acts performed throughout history.\",\n",
        "        \"The origin of circuses can be traced back to ancient Rome, where the first recorded circus-like event took place in 6th century BCE. The Circus Maximus, a large stadium built for chariot racing and other spectacles, was the center of Roman entertainment. However, these early events were not what we consider as modern circuses today; they mainly focused on horse and chariot races, athletic competitions, and staged battles.\\n\\nThe modern concept of the circus began to take shape in the late 18th century when Englishman Philip Astley, a former cavalry sergeant major, established the first permanent circular arena or \\\"ring\\\" for equestrian performances in London in 1768. He combined daring horsemanship with acrobatics, clowning, and music, creating a new form of popular entertainment that would become known as the circus.\\n\\nIn the early 19th century, the circus spread across Europe and North America, evolving into various forms and incorporating different acts. Tightrope walkers, jugglers, trapeze artists, and animal trainers became regular features of the circus, alongside equestrian acts and clowns. One significant milestone was the introduction of the circus tent by American showman Joshua Purdy Brown in the 1820s, which allowed circuses to travel more easily and perform in temporary venues.\\n\\nP.T. Barnum is another key figure in the evolution of the circus. In the mid-19th century, he founded the famous Barnum & Bailey Circus, which eventually merged with the Ringling Brothers Circus to create the largest traveling circus in the United States. Barnum's circus featured elaborate costumes, exotic animals, and human oddities, making it a spectacle unlike anything seen before.\\n\\nThroughout the 20th century, the circus continued to evolve, adapting to changing tastes and technologies. Traditional animal acts began to decline due to growing concerns about animal welfare, leading to an increased focus on human performances. Cirque du Soleil, founded in 1984 by Guy LalibertÃ© and Daniel Gauthier, is a prime example of this shift. The Canadian company revolutionized the circus industry with its innovative blend of acrobatics, dance, music, and theatrical elements, creating a more artistic and sophisticated form of entertainment.\\n\\nIn recent years, there has been a resurgence of interest in smaller, more intimate circuses that emphasize skilled human performers and unique acts. These contemporary circuses often incorporate elements of street performance, cabaret, and live music, offering an alternative to the large-scale productions of traditional circuses.\\n\\nIn conclusion, the origin and evolution of circuses have seen significant milestones and changes in the types of acts performed throughout history. From ancient Roman spectacles to modern-day artistic performances, the circus has continually adapted to reflect societal values and entertain audiences worldwide.\",\n",
        "        \"Describe how circuses originated and evolved, outlining important milestones and how their types of acts have changed throughout history.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Given the sentence \\\"Three men go for a ride in a boat.\\\" is it true that \\\"The three men are on a large sailboat.\\\"?\\nLet's solve step-by-step:\",\n",
        "        \"Step 1: Analyze the given sentence\\nThe given sentence is \\\"Three men go for a ride in a boat.\\\" This tells us that there are three men and they are going for a ride in a boat. However, the type and size of the boat are not specified.\\n\\nStep 2: Compare the given sentence with the statement\\nThe statement is \\\"The three men are on a large sailboat.\\\" This statement provides additional information about the boat - that it is a large sailboat.\\n\\nStep 3: Determine if the statement is true based on the given sentence\\nSince the given sentence does not specify the type or size of the boat, we cannot determine if the statement is true or false based on the information provided. There is not enough information in the given sentence to confirm that the three men are on a large sailboat. \\n\\nConclusion:\\nBased on the given sentence, we cannot conclude that \\\"The three men are on a large sailboat.\\\" There is not enough information provided to determine the truth of the statement.\",\n",
        "        \"Given the sentence \\\"Three men go for a ride in a boat,\\\" can we conclude they are on a large sailboat?. Solve step-by-step:\"\n",
        "    ),\n",
        "    (\n",
        "       \"What are the forces responsible for the Earth's orbit around the Sun, and how do they interact?\",\n",
        "       \"The two forces responsible for the Earth's orbit around the Sun are gravitational force and centrifugal force. Gravitational force, according to the Law of Universal Gravity, attracts the Earth towards the Sun. Centrifugal force, a fictitious force, acts outwards from the Sun. These two forces balance each other, resulting in the Earth's stable orbit around the Sun.\",\n",
        "       \"Which forces shape the Earth's orbit around the Sun, and what are their interactions?\"\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "x8Ly99yhjUzj",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997836115,
          "user_tz": -60,
          "elapsed": 33,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        }
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "\n",
        "# Initialize S-BERT model once\n",
        "# 'all-MiniLM-L6-v2' is a common, fast, and effective choice for general English text\n",
        "SBERT_MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "def calculate_sbert_cosine_similarity(text1, text2, model=SBERT_MODEL):\n",
        "    \"\"\"\n",
        "    Calculates Cosine Similarity between two strings using Sentence-BERT embeddings.\n",
        "    Returns score between -1 and 1, where 1.0 means perfect semantic similarity.\n",
        "    \"\"\"\n",
        "    if not text1 or not text2:\n",
        "        return 0.0\n",
        "\n",
        "    # Generate dense vector embeddings for both texts\n",
        "    embeddings1 = model.encode(text1)\n",
        "    embeddings2 = model.encode(text2)\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    similarities = model.similarity(embeddings1, embeddings2)\n",
        "    return float(similarities[0][0])\n",
        "\n",
        "def calculate_rouge_l_recall(reference, hypothesis):\n",
        "    \"\"\"\n",
        "    Calculates ROUGE-L Recall score.\n",
        "    Returns score between 0 and 1, where 1.0 means perfect recall.\n",
        "    \"\"\"\n",
        "    if not reference or not hypothesis:\n",
        "        return 0.0\n",
        "\n",
        "    # Use use_stemmer=True for better matching\n",
        "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(reference, hypothesis)\n",
        "\n",
        "    # Extract the Recall score\n",
        "    return scores['rougeL'].recall\n",
        "\n",
        "def evaluate(model, tokenizer, prompts, csv_path):\n",
        "    outputs = []\n",
        "\n",
        "    for original_prompt, expected_answer, modified_prompt in prompts:\n",
        "        messages = [{\"role\": \"user\", \"content\": modified_prompt}]\n",
        "\n",
        "        inputs = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        output_tokens = model.generate(\n",
        "            input_ids=inputs,\n",
        "            temperature=1.5,\n",
        "            min_p=0.1,\n",
        "            max_new_tokens=2048,\n",
        "        )\n",
        "\n",
        "        decoded_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
        "        assistant_start = decoded_output.find(\"assistant\\n\\n\")\n",
        "        assistant_output = decoded_output[assistant_start + len(\"assistant\\n\\n\"):].strip()\n",
        "\n",
        "        # --- Metric Calculation ---\n",
        "\n",
        "        # 1. Semantic Similarity (Sentence-BERT Cosine Sim)\n",
        "        sbert_cosine_sim = calculate_sbert_cosine_similarity(\n",
        "            expected_answer,\n",
        "            assistant_output\n",
        "        )\n",
        "\n",
        "        # 2. Content Coverage (ROUGE-L Recall)\n",
        "        rouge_l_recall = calculate_rouge_l_recall(\n",
        "            expected_answer,\n",
        "            assistant_output\n",
        "        )\n",
        "\n",
        "        outputs.append({\n",
        "            \"original_prompt\": original_prompt,\n",
        "            \"expected_answer\": expected_answer,\n",
        "            \"modified_prompt\": modified_prompt,\n",
        "            \"actual_output\": assistant_output,\n",
        "            \"sbert_cosine_sim\": sbert_cosine_sim,\n",
        "            \"rouge_l_recall\": rouge_l_recall,\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(outputs)\n",
        "\n",
        "    # Clean strings before saving to CSV\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == object:\n",
        "            df[col] = df[col].astype(str).str.replace('\\n', '\\\\n').str.replace('\\r', '\\\\r')\n",
        "\n",
        "    df.to_csv(csv_path, index=False, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "3flRfEa0lmFp",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997842502,
          "user_tz": -60,
          "elapsed": 6387,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "c5547ca0edab46c3bb344a1bdb5719e0",
            "8a25fa269c7b4b0e88c36d1b28b60fa2",
            "c8bd8d8945f843a787518e5653979552",
            "eab3f7e01af2455aba1a78341c7ecc0a",
            "2eafdd44c9f84505bc094d5d7994542f",
            "7fa64d9acd894ab1b75c7a9abc3376c8",
            "786d17b8855a43d09ab9b97cf3b06bc6",
            "5ab7c59e26fb45eca7a2b13106194ae6",
            "4040c9c62a4942698955e4a7bc1c642f",
            "2e153dc7c0ec4e36b1e0bfee4dd55375",
            "1944d257cb7c4f90b8e12b4001e96332",
            "ff8f43917d594f45a0c06a508757f53f",
            "7ab3aad769f549128e08b1e5b1a2735c",
            "19ed84486ccc497a9c3300bf5ba88e79",
            "6079e665b740406dad235de7bbd50a49",
            "8c4c7d9cc8bc4cf68edc94a2dc74ac7e",
            "7edb73452323480999945910e78534dc",
            "64cd6341491745118a396ef4d9d2ed6e",
            "5d8d869e1d1e48948cb82628f85f6f39",
            "85761872a3954594a2d3a08156a8592c",
            "6d77461596d741ba8c68e1ebc41d6bcc",
            "2ebffb15b4ac4396a2db8815adf88362",
            "36d5597ebd3c49868fe9185224756453",
            "631b7edb7e964d7ba23d273c4a120146",
            "38d895012dbf40269b99f2146dd20e7d",
            "9f6a5c2fc0e34f5ab35ed75f28c140ee",
            "5a1eee9979dc4be8878d89d0ec74bdb9",
            "2139643c215b4b09aec7dfb100e00e7a",
            "a25d0ca27f5e4587b5e9d314a81b1224",
            "cae53152363b476e9da673bb6155313b",
            "537dbacc0410498f866c0e330a885247",
            "3507181691744da5a55fe977aa0005a1",
            "2b0d20e3df914055adb17bb5bf9c9f80",
            "219297aedc6a411a83ed54102ab75e54",
            "e5765865e0dd4988b9e449f7f7f75362",
            "b19bcdfc3fb84ad8a86654536a8ecdc0",
            "9f51fa92d4044fdfb954bd27d3e77ff2",
            "d1da7784b4194b088c741f14d4b8720f",
            "976f870907d546ab889439b369a60ee2",
            "a26d222876264fb79fc6b81a759c5393",
            "dd4a9fed23ed4464906cd0bfe58ed57f",
            "e28ceeec61444e14a7c467758548eefd",
            "248637f9f3c44361ab25c81a372dfbca",
            "3df0c8c7326444caa1c6e73583c90782",
            "b6b421a23c914612ad61c6d61bdd2646",
            "0fe16656ffcd4f09baa25d6c0f689ae3",
            "2eb2a16032be4faa9d6cde0a798b1e83",
            "c02273f137614a759a6bfb31b3c4d0e2",
            "a5e4e2d7cb644626a39907e05e3e211c",
            "8348deb1ae2343a28b97b7bead57e61a",
            "c3cba296ce90412d86dbf8fbc90e0860",
            "e5f570bb36f1444686ccbad7d3b90da4",
            "e49e1a13190144bcbb1f598f98692b10",
            "e52f1f2a64dc4964abb9250b096beceb",
            "883a803320c5407a9bad3f8bdff8f317",
            "e2366db1184748869342861d877a5d1c",
            "d8af4c5bd8744fb8a2c43e44b9d95523",
            "4742013038544adcad8a1bef8f10d61e",
            "9f7acf257c4c4bdab1c6faed23f9e60b",
            "bf58e86e679c4d1c86e799e820440885",
            "0472f28b124b4648b26e671cd60bc34e",
            "4f40e6ce21414f719112a409ec5a8892",
            "3caf7f90101c4935bdcab7cf9a915317",
            "98a1c93750974601ad8fbd2856f02ce8",
            "0c815f267b8142e79c74da5c238c5a04",
            "26e97d7ff60445dc9f1d1a3f7f7c5211",
            "13ae8ef17ad8438ab72411449b69e725",
            "450f8ddfc23948ce89b3fa4e90eaa3c3",
            "7b08d81a74744e0b8508173f40cd26f6",
            "4f34aa759bd24a69826346392c337dfe",
            "788d82029eec4d5b854490232aa78e65",
            "a14aa29f532640c994e26729d6b2f809",
            "298eaaa8fe3e454b843866bbc2c7437e",
            "60a5ac5b88fe4272ae904071b1be107f",
            "21a92e17d82a45e59ff7b9bd675380e1",
            "acdae105cbff446d8d5d8e08a400027a",
            "aa533140ab3647929412641a129ce9f4",
            "50a06fce85bd454b82faf3971de04bdf",
            "721230ae5e1e42c3897521c7b3fd66e1",
            "58a10a4f000a48daa33053579361d759",
            "630f882073094f69ae2e0f3db0b7c5d7",
            "20f79ccc24274f85949e194e0d20cfd8",
            "97dc3fd125eb4b4da9301a8f5e2081a5",
            "30a40f72640b433da04b9e7431f6da06",
            "955cb18d61b6490da8f45545fa35ad95",
            "a474d1dbcbf84d3793825441b6237d7c",
            "67cf5725bddd41628c020347cc10b43a",
            "cdeee2974efe4666ab2508ec03c03a17",
            "8c3afe83809c4beca28484794f55ff48",
            "a8408a67933543839df7577b5b7f02bb",
            "c369cf28c2e7449699214126a831cd8d",
            "b38db1c0901b49e5b88b069d87618d6f",
            "2bd1af14c9d64a2eac78b4e7e6746fe4",
            "f7da8ac39b5f48fdac904aee009e1d44",
            "0f264caf853d45ce85ffc6839eeed766",
            "9eb2f14436f8473493983e5148c65a67",
            "49e5b9eb73894f18abd7269883beafbd",
            "f7e9d04f426b435fb9f08c4743438efc",
            "e1d0048f27314d73909e8b539fac6dd8",
            "7b8316a5b30549efb1694a1a5712ed37",
            "8c83e36d4f2c4b8084197a822969d563",
            "2a2a28b4ef35415c89b13c28b6806e3b",
            "48fb1d2da1f849f5806d665cbdbc3bb5",
            "47a4ff3eb3424e758ef71dc0458097f3",
            "9e7c09f094384c9a9f05382a4f465583",
            "8d1548a0605149ac87e64500ce5549cd",
            "b86edbc7db454798ae40d39b9ec938ec",
            "636d655306b64ee4a253f8c9071a95fe",
            "12c89c59d60a4006a566b052edba528f",
            "e2ec5ed5d3bf4bb2b63621eef169ca84",
            "ad621c17fcde46ab88ce860537698314",
            "5c6307f172eb40dc92b212c4e00a60c4",
            "ff0514fb98c9452591f3a23078b809d0",
            "d3ecfd2afdb6476b9d4cd91b99bdea26",
            "6ce0af8ae54a42d38dadeec7b129f796",
            "e5f800068ac14b2e92ab4c6cdb63671d",
            "3abd945236b54c69aa3b36d46baecd90",
            "ddcc0b31f6954f36a4d695afae9c97e6",
            "2589d4c3c3484549acdbdc5c2dc5a7a1",
            "ae163d28a26c4cacb0e0e990f9c9e534",
            "b1bdb7f0a7f847f2a65d20aac7402b80"
          ]
        },
        "outputId": "3f3c1af9-5a0a-4da3-8a9b-d980ab7f0075"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5547ca0edab46c3bb344a1bdb5719e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff8f43917d594f45a0c06a508757f53f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36d5597ebd3c49868fe9185224756453"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "219297aedc6a411a83ed54102ab75e54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b421a23c914612ad61c6d61bdd2646"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2366db1184748869342861d877a5d1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13ae8ef17ad8438ab72411449b69e725"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50a06fce85bd454b82faf3971de04bdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c3afe83809c4beca28484794f55ff48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b8316a5b30549efb1694a1a5712ed37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad621c17fcde46ab88ce860537698314"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "base_model, base_tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = BASE_MODEL_NAME,\n",
        "    max_seq_length = MAX_SEQ_LENGTH,\n",
        "    dtype = D_TYPE,\n",
        "    load_in_4bit = LOAD_IN_4BIT,\n",
        ")\n",
        "FastLanguageModel.for_inference(base_model)\n",
        "FastLanguageModel.for_inference(model)"
      ],
      "metadata": {
        "id": "cTZY8NteKwP2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764997852503,
          "user_tz": -60,
          "elapsed": 9987,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        }
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(base_model, base_tokenizer, prompts, f\"{CHECKPOINT_DIR}/base_eval.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d2dBkzSeDIry",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764998122258,
          "user_tz": -60,
          "elapsed": 269753,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "b1574be0-920d-424e-8ba0-d1a6d11e348d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      original_prompt  \\\n",
              "0   Discuss the efforts of the United Nations to a...   \n",
              "1   Why is a wing necessary for flight, given that...   \n",
              "2   How can I plot a circle with matplotlib.pyplot...   \n",
              "3   Discuss two practical and cost-effective ways ...   \n",
              "4   Explain the chain of events leading to the sig...   \n",
              "5                   How is stellar parallax measured?   \n",
              "6   What is bacterial transformation, and how does...   \n",
              "7     What triggers the release of neurotransmitters?   \n",
              "8   How does a processor execute an assembly instr...   \n",
              "9   How do protons overcome their repulsion and co...   \n",
              "10  Develop an all-encompassing strategy that take...   \n",
              "11  Discuss the origin and evolution of circuses, ...   \n",
              "12  Given the sentence \"Three men go for a ride in...   \n",
              "13  What are the forces responsible for the Earth'...   \n",
              "\n",
              "                                      expected_answer  \\\n",
              "0   The United Nations is a global organization wi...   \n",
              "1   The wing serves a crucial role in flight effic...   \n",
              "2   The circle object that you created using `plt....   \n",
              "3   Solution 1: Implementing Renewable Energy Sour...   \n",
              "4   1. King John's rule: King John of England face...   \n",
              "5   Stellar parallax is measured by observing the ...   \n",
              "6   Bacterial transformation is a genetic modifica...   \n",
              "7   The axon is a long, thin projection that exten...   \n",
              "8   To understand how a processor performs the add...   \n",
              "9   When protons are initially far apart, they pos...   \n",
              "10  To encourage the adoption of sustainable agric...   \n",
              "11  The origin of circuses can be traced back to a...   \n",
              "12  Step 1: Analyze the given sentence\\nThe given ...   \n",
              "13  The two forces responsible for the Earth's orb...   \n",
              "\n",
              "                                      modified_prompt  \\\n",
              "0   Describe the United Nationsâ€™ efforts aimed at ...   \n",
              "1   Why are wings essential for flight if engines ...   \n",
              "2   How can I draw a circle in matplotlib using on...   \n",
              "3   Examine two practical and affordable strategie...   \n",
              "4   Outline the sequence of events that led to the...   \n",
              "5              How does one measure stellar parallax?   \n",
              "6   What is bacterial transformation, and through ...   \n",
              "7   What causes neurons to release neurotransmitters?   \n",
              "8   How does a processor turn an assembly instruct...   \n",
              "9   How do protons manage to overcome their mutual...   \n",
              "10  Create a comprehensive strategy that considers...   \n",
              "11  Describe how circuses originated and evolved, ...   \n",
              "12  Given the sentence \"Three men go for a ride in...   \n",
              "13  Which forces shape the Earth's orbit around th...   \n",
              "\n",
              "                                        actual_output  sbert_cosine_sim  \\\n",
              "0   The United Nations (UN) has made significant e...          0.753761   \n",
              "1   Although engines provide the necessary energy ...          0.675520   \n",
              "2   Here's a function to plot a circle using matpl...          0.721404   \n",
              "3   **Strategy 1: Promoting Renewable Energy Techn...          0.724846   \n",
              "4   Here is the outline of events that led to the ...          0.799022   \n",
              "5   Measuring stellar parallax is a fascinating te...          0.831019   \n",
              "6   Bacterial transformation is a process by which...          0.894761   \n",
              "7   Neurons release neurotransmitters in response ...          0.666789   \n",
              "8   The process of turning an assembly instruction...          0.811062   \n",
              "9   You're right to be puzzled by the fact that pr...          0.679870   \n",
              "10  **Comprehensive Strategy for Sustainable Agric...          0.787188   \n",
              "11  The circus, a form of entertainment that combi...          0.600823   \n",
              "12  To analyze the given sentence, we can break it...          0.858573   \n",
              "13  The Earth's orbit around the Sun is primarily ...          0.801864   \n",
              "\n",
              "    rouge_l_recall  \n",
              "0         0.304348  \n",
              "1         0.246964  \n",
              "2         0.228972  \n",
              "3         0.210396  \n",
              "4         0.270677  \n",
              "5         0.289941  \n",
              "6         0.262295  \n",
              "7         0.202020  \n",
              "8         0.230769  \n",
              "9         0.264000  \n",
              "10        0.186813  \n",
              "11        0.178490  \n",
              "12        0.314286  \n",
              "13        0.593220  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd3db7f2-6055-4eca-b4ce-2ba08649aed3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_prompt</th>\n",
              "      <th>expected_answer</th>\n",
              "      <th>modified_prompt</th>\n",
              "      <th>actual_output</th>\n",
              "      <th>sbert_cosine_sim</th>\n",
              "      <th>rouge_l_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Discuss the efforts of the United Nations to a...</td>\n",
              "      <td>The United Nations is a global organization wi...</td>\n",
              "      <td>Describe the United Nationsâ€™ efforts aimed at ...</td>\n",
              "      <td>The United Nations (UN) has made significant e...</td>\n",
              "      <td>0.753761</td>\n",
              "      <td>0.304348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is a wing necessary for flight, given that...</td>\n",
              "      <td>The wing serves a crucial role in flight effic...</td>\n",
              "      <td>Why are wings essential for flight if engines ...</td>\n",
              "      <td>Although engines provide the necessary energy ...</td>\n",
              "      <td>0.675520</td>\n",
              "      <td>0.246964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I plot a circle with matplotlib.pyplot...</td>\n",
              "      <td>The circle object that you created using `plt....</td>\n",
              "      <td>How can I draw a circle in matplotlib using on...</td>\n",
              "      <td>Here's a function to plot a circle using matpl...</td>\n",
              "      <td>0.721404</td>\n",
              "      <td>0.228972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Discuss two practical and cost-effective ways ...</td>\n",
              "      <td>Solution 1: Implementing Renewable Energy Sour...</td>\n",
              "      <td>Examine two practical and affordable strategie...</td>\n",
              "      <td>**Strategy 1: Promoting Renewable Energy Techn...</td>\n",
              "      <td>0.724846</td>\n",
              "      <td>0.210396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Explain the chain of events leading to the sig...</td>\n",
              "      <td>1. King John's rule: King John of England face...</td>\n",
              "      <td>Outline the sequence of events that led to the...</td>\n",
              "      <td>Here is the outline of events that led to the ...</td>\n",
              "      <td>0.799022</td>\n",
              "      <td>0.270677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How is stellar parallax measured?</td>\n",
              "      <td>Stellar parallax is measured by observing the ...</td>\n",
              "      <td>How does one measure stellar parallax?</td>\n",
              "      <td>Measuring stellar parallax is a fascinating te...</td>\n",
              "      <td>0.831019</td>\n",
              "      <td>0.289941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is bacterial transformation, and how does...</td>\n",
              "      <td>Bacterial transformation is a genetic modifica...</td>\n",
              "      <td>What is bacterial transformation, and through ...</td>\n",
              "      <td>Bacterial transformation is a process by which...</td>\n",
              "      <td>0.894761</td>\n",
              "      <td>0.262295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What triggers the release of neurotransmitters?</td>\n",
              "      <td>The axon is a long, thin projection that exten...</td>\n",
              "      <td>What causes neurons to release neurotransmitters?</td>\n",
              "      <td>Neurons release neurotransmitters in response ...</td>\n",
              "      <td>0.666789</td>\n",
              "      <td>0.202020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does a processor execute an assembly instr...</td>\n",
              "      <td>To understand how a processor performs the add...</td>\n",
              "      <td>How does a processor turn an assembly instruct...</td>\n",
              "      <td>The process of turning an assembly instruction...</td>\n",
              "      <td>0.811062</td>\n",
              "      <td>0.230769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How do protons overcome their repulsion and co...</td>\n",
              "      <td>When protons are initially far apart, they pos...</td>\n",
              "      <td>How do protons manage to overcome their mutual...</td>\n",
              "      <td>You're right to be puzzled by the fact that pr...</td>\n",
              "      <td>0.679870</td>\n",
              "      <td>0.264000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Develop an all-encompassing strategy that take...</td>\n",
              "      <td>To encourage the adoption of sustainable agric...</td>\n",
              "      <td>Create a comprehensive strategy that considers...</td>\n",
              "      <td>**Comprehensive Strategy for Sustainable Agric...</td>\n",
              "      <td>0.787188</td>\n",
              "      <td>0.186813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Discuss the origin and evolution of circuses, ...</td>\n",
              "      <td>The origin of circuses can be traced back to a...</td>\n",
              "      <td>Describe how circuses originated and evolved, ...</td>\n",
              "      <td>The circus, a form of entertainment that combi...</td>\n",
              "      <td>0.600823</td>\n",
              "      <td>0.178490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Given the sentence \"Three men go for a ride in...</td>\n",
              "      <td>Step 1: Analyze the given sentence\\nThe given ...</td>\n",
              "      <td>Given the sentence \"Three men go for a ride in...</td>\n",
              "      <td>To analyze the given sentence, we can break it...</td>\n",
              "      <td>0.858573</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What are the forces responsible for the Earth'...</td>\n",
              "      <td>The two forces responsible for the Earth's orb...</td>\n",
              "      <td>Which forces shape the Earth's orbit around th...</td>\n",
              "      <td>The Earth's orbit around the Sun is primarily ...</td>\n",
              "      <td>0.801864</td>\n",
              "      <td>0.593220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd3db7f2-6055-4eca-b4ce-2ba08649aed3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd3db7f2-6055-4eca-b4ce-2ba08649aed3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd3db7f2-6055-4eca-b4ce-2ba08649aed3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86212969-83b4-483d-9cda-b0574aab713b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86212969-83b4-483d-9cda-b0574aab713b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86212969-83b4-483d-9cda-b0574aab713b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"evaluate(base_model, base_tokenizer, prompts, f\\\"{CHECKPOINT_DIR}/base_eval\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"original_prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"How do protons overcome their repulsion and come close enough to form a nucleus, considering the short range of nuclear forces?\",\n          \"Discuss the origin and evolution of circuses, touching on significant milestones and changes in the types of acts performed throughout history.\",\n          \"Discuss the efforts of the United Nations to advance world peace.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expected_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"When protons are initially far apart, they possess sufficient kinetic energy to approach each other despite the electrostatic repulsion between them. As they get closer, they can experience a quantum mechanical phenomenon called tunneling, which allows them to pass through the energy barrier that would normally keep them apart due to their repulsion. Once they tunnel through this barrier, the strong nuclear force becomes significant, and the protons can be held together within a nucleus.\\\\n\\\\nIn some cases, this results in a temporary diproton nucleus, which is unstable. A process called beta decay occurs, where one of the protons converts into a neutron, forming a stable deuterium nucleus (deuteron). This deuteron can then participate in further nuclear fusion reactions, like those that power the sun.\",\n          \"The origin of circuses can be traced back to ancient Rome, where the first recorded circus-like event took place in 6th century BCE. The Circus Maximus, a large stadium built for chariot racing and other spectacles, was the center of Roman entertainment. However, these early events were not what we consider as modern circuses today; they mainly focused on horse and chariot races, athletic competitions, and staged battles.\\\\n\\\\nThe modern concept of the circus began to take shape in the late 18th century when Englishman Philip Astley, a former cavalry sergeant major, established the first permanent circular arena or \\\"ring\\\" for equestrian performances in London in 1768. He combined daring horsemanship with acrobatics, clowning, and music, creating a new form of popular entertainment that would become known as the circus.\\\\n\\\\nIn the early 19th century, the circus spread across Europe and North America, evolving into various forms and incorporating different acts. Tightrope walkers, jugglers, trapeze artists, and animal trainers became regular features of the circus, alongside equestrian acts and clowns. One significant milestone was the introduction of the circus tent by American showman Joshua Purdy Brown in the 1820s, which allowed circuses to travel more easily and perform in temporary venues.\\\\n\\\\nP.T. Barnum is another key figure in the evolution of the circus. In the mid-19th century, he founded the famous Barnum & Bailey Circus, which eventually merged with the Ringling Brothers Circus to create the largest traveling circus in the United States. Barnum's circus featured elaborate costumes, exotic animals, and human oddities, making it a spectacle unlike anything seen before.\\\\n\\\\nThroughout the 20th century, the circus continued to evolve, adapting to changing tastes and technologies. Traditional animal acts began to decline due to growing concerns about animal welfare, leading to an increased focus on human performances. Cirque du Soleil, founded in 1984 by Guy Lalibert\\u00e9 and Daniel Gauthier, is a prime example of this shift. The Canadian company revolutionized the circus industry with its innovative blend of acrobatics, dance, music, and theatrical elements, creating a more artistic and sophisticated form of entertainment.\\\\n\\\\nIn recent years, there has been a resurgence of interest in smaller, more intimate circuses that emphasize skilled human performers and unique acts. These contemporary circuses often incorporate elements of street performance, cabaret, and live music, offering an alternative to the large-scale productions of traditional circuses.\\\\n\\\\nIn conclusion, the origin and evolution of circuses have seen significant milestones and changes in the types of acts performed throughout history. From ancient Roman spectacles to modern-day artistic performances, the circus has continually adapted to reflect societal values and entertain audiences worldwide.\",\n          \"The United Nations is a global organization with a mission to promote international peace and security. Since its founding in 1945, the United Nations has been a major force in global diplomacy, working to resolve conflicts both on a regional and international level. The United Nations has organized peacekeeping missions and negotiated ceasefires, arms embargoes and disarmament agreements in countries around the world. The United Nations also works to provide humanitarian and economic assistance to areas affected by war, famine, and natural disasters. The United Nations also seeks to promote human rights and gender equality, uphold international law and advocate for global economic and social justice. By providing a forum for dialogue and discussion between member states, the United Nations seeks to advance dialogue and constructively address issues that have the potential to lead to conflict and war.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modified_prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"How do protons manage to overcome their mutual repulsion and get close enough to make a nucleus, given the nuclear force\\u2019s short range?\",\n          \"Describe how circuses originated and evolved, outlining important milestones and how their types of acts have changed throughout history.\",\n          \"Describe the United Nations\\u2019 efforts aimed at promoting global peace.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual_output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"You're right to be puzzled by the fact that protons, which are positively charged particles, manage to come together and form a nucleus despite their mutual repulsion. This is indeed a fundamental aspect of nuclear physics. Here are some key reasons why protons can overcome their mutual repulsion:\\\\n\\\\n1. **The nuclear force**: Also known as the strong nuclear force, it's a fundamental force of nature that holds protons, neutrons, and other particles together inside atomic nuclei. The nuclear force is mediated by particles called gluons and is responsible for overcoming the mutual repulsion of charged particles.\\\\n2. **Short range, but strong**: The nuclear force has a very short range (on the order of 1-2 femtometers) due to its exchange nature. However, when two protons are close enough, the attractive nuclear force overcomes the repulsive electrostatic force, holding the protons together.\\\\n3. **Screening by electrons and other particles**: Electrons surrounding the nucleus help to neutralize the positive charge of the protons, reducing the repulsion. Neutrons also play a crucial role in contributing to the overall repulsion of the nucleus, while their small size and weak interaction with the nucleus also help to keep the nuclear distance reasonable.\\\\n4. **Dealing with quantum mechanics**: At the atomic and subatomic scales, quantum mechanics plays a significant role. In this context, particles can occupy multiple energy states simultaneously, which helps to explain why the nuclear force is not only strong but also relatively stable, despite its short range.\\\\n5. **Confining effects**: The presence of the nuclear force and the other particles' effects within the nucleus lead to the confining of the protons and neutrons, which ultimately results in the formation of a stable nucleus. \\\\n\\\\nTo sum up, it is the combination of the strong nuclear force, the relative proximity of the protons within the nuclear distance, and the effects of electrons and other particles that allow the mutual repulsion of protons to be overcome. This leads to the formation of stable nuclei in atoms.\",\n          \"The circus, a form of entertainment that combines acrobatics, aerial performances, animal acts, and other thrilling elements, has a rich and diverse history spanning thousands of years. Here's an overview of its origins, evolution, and significant milestones:\\\\n\\\\n**Ancient Origins (3000 BCE - 500 CE)**\\\\n\\\\n* The concept of circus-like performances dates back to ancient civilizations such as Egypt, Greece, and Rome. These performances often involved traveling troupes, acrobats, jugglers, and animal exhibits.\\\\n* The Roman Empire's \\\"Glorietae\\\" (literally \\\"games\\\") were elaborate performances featuring acrobats, troupes, and sometimes even gladiators.\\\\n\\\\n**Middle Ages to Renaissance (500 CE - 1800 CE)**\\\\n\\\\n* During the Middle Ages, traveling fairs and festivals became popular, featuring jugglers, acrobats, and musicians. The Jesters and Troubadours played important roles in entertainment.\\\\n* In Italy, the Commedia dell'Arte developed, with performers like Commedia dell'Arte (the 'physical clown) that performed in theatrical settings.\\\\n* Jugglers, acrobats, and aerialists became common in Europe and Asia, while traveling theater companies and fairs emerged in various countries.\\\\n\\\\n**Circus Evolution (1800 CE - 1900 CE)**\\\\n\\\\n* In 1768, Philip Astley founded the first modern circus in London, England. The modern circus evolved into three main styles:\\\\n\\t+ The English Ring (where horse riding, juggling and acrobatic events were staged, set up in rings and often associated with jousting and horseback riding acts)\\\\n\\t+ The Wild West style circus, and the circus in general has many of these sub-genres today, from the original Astley to the modern circus today that blends styles \\\\n\\t+ Circus shows emerged from European folk traditions, incorporating music and dance into a narrative, in order to further connect the performances for audiences of Europe.\\\\n\\\\n**20th Century Circus Evolution (1900 CE - 2000 CE)**\\\\n\\\\n* 1950s-60s: The Golden Age of the Circus saw a rise in popularity, with circus performances becoming more commercialized and televised.\\\\n* 1970s-80s: The counterculture movement influenced the circus, with more experimental and avant-garde performances emerging.\\\\n* 1990s: The circus began to evolve as a form of art, with a focus on storytelling and visual presentation.\\\\n\\\\n**21st Century Circus (2000 CE - present)**\\\\n\\\\n* Modern circus performers blend traditional circus skills with contemporary music, dance, and theater, creating diverse and dynamic performances.\\\\n* Circus arts have become an essential part of popular culture, with circus performances incorporating a wide range of themes and styles, such as high-tech production, aerial stunts, and themed circus.\\\\n* The circus has become a versatile and ever-changing medium, with continuous innovations in technology, design, and performance techniques, evolving further today in all the mediums with artistry, creativity and innovative and experimental elements that it embodies.\",\n          \"The United Nations (UN) has made significant efforts to promote global peace and address conflicts throughout its history. Some key initiatives include:\\\\n\\\\n1. The Declaration of the United Nations: This document, adopted in 1948, sets forth the principles and purposes of the UN, including the pursuit of lasting peace and security.\\\\n\\\\n2. The Peace Bureau: Founded by International Peace Bureau in 1920, now operating under the United Nations' Department of Economic and Social Affairs, it works to create international peace and disarmament by building partnerships and advancing disarmament initiatives.\\\\n\\\\n3. Peacekeeping: The UN has deployed peacekeeping forces in various parts of the world to prevent conflicts, stabilize fragile societies, and support the rule of law.\\\\n\\\\n4. Special Representatives of the Secretary-General (SRSG): This office, established in 2008, is designed to serve as a voice for the victims of crimes and their communities.\\\\n\\\\n5. Security Council Resolutions: The UN Security Council has passed numerous resolutions aiming to prevent conflict and resolve crises through negotiations.\\\\n\\\\n6. Sustainable Peace Initiatives: The UN works to build resilience through sustainable peace initiatives, focusing on factors like economic development, human rights, and education to build stable and secure societies.\\\\n\\\\n7. High-Level Panels: Various high-level panels have been formed throughout the UN's history, including those related to post-conflict reconstruction, women's empowerment, and UN reform.\\\\n\\\\n8. UN-led Reconciliation and Post-Conflict Reconstruction Initiatives: Various initiatives under the UN, like the Truth and Reconciliation Commissions, the Humanitarian Response Bureau, and various country-specific post-conflict reconstruction efforts, are used to foster lasting peace through understanding past atrocities and facilitating rebuilding.\\\\n\\\\nDespite these efforts, there is still much work to be done to create lasting peace and global security, and the UN continues to evolve and adapt its initiatives to respond to emerging challenges.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sbert_cosine_sim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08311742095444206,\n        \"min\": 0.6008225679397583,\n        \"max\": 0.8947608470916748,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6798699498176575,\n          0.6008225679397583,\n          0.7537609338760376\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge_l_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10202798050103541,\n        \"min\": 0.17848970251716248,\n        \"max\": 0.5932203389830508,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.264,\n          0.17848970251716248,\n          0.30434782608695654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, tokenizer, prompts, f\"{CHECKPOINT_DIR}/eval.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nSBWsnviDKy9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764998412640,
          "user_tz": -60,
          "elapsed": 290380,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "outputId": "568b7907-b696-49e5-b29d-419589fbd4e7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      original_prompt  \\\n",
              "0   Discuss the efforts of the United Nations to a...   \n",
              "1   Why is a wing necessary for flight, given that...   \n",
              "2   How can I plot a circle with matplotlib.pyplot...   \n",
              "3   Discuss two practical and cost-effective ways ...   \n",
              "4   Explain the chain of events leading to the sig...   \n",
              "5                   How is stellar parallax measured?   \n",
              "6   What is bacterial transformation, and how does...   \n",
              "7     What triggers the release of neurotransmitters?   \n",
              "8   How does a processor execute an assembly instr...   \n",
              "9   How do protons overcome their repulsion and co...   \n",
              "10  Develop an all-encompassing strategy that take...   \n",
              "11  Discuss the origin and evolution of circuses, ...   \n",
              "12  Given the sentence \"Three men go for a ride in...   \n",
              "13  What are the forces responsible for the Earth'...   \n",
              "\n",
              "                                      expected_answer  \\\n",
              "0   The United Nations is a global organization wi...   \n",
              "1   The wing serves a crucial role in flight effic...   \n",
              "2   The circle object that you created using `plt....   \n",
              "3   Solution 1: Implementing Renewable Energy Sour...   \n",
              "4   1. King John's rule: King John of England face...   \n",
              "5   Stellar parallax is measured by observing the ...   \n",
              "6   Bacterial transformation is a genetic modifica...   \n",
              "7   The axon is a long, thin projection that exten...   \n",
              "8   To understand how a processor performs the add...   \n",
              "9   When protons are initially far apart, they pos...   \n",
              "10  To encourage the adoption of sustainable agric...   \n",
              "11  The origin of circuses can be traced back to a...   \n",
              "12  Step 1: Analyze the given sentence\\nThe given ...   \n",
              "13  The two forces responsible for the Earth's orb...   \n",
              "\n",
              "                                      modified_prompt  \\\n",
              "0   Describe the United Nationsâ€™ efforts aimed at ...   \n",
              "1   Why are wings essential for flight if engines ...   \n",
              "2   How can I draw a circle in matplotlib using on...   \n",
              "3   Examine two practical and affordable strategie...   \n",
              "4   Outline the sequence of events that led to the...   \n",
              "5              How does one measure stellar parallax?   \n",
              "6   What is bacterial transformation, and through ...   \n",
              "7   What causes neurons to release neurotransmitters?   \n",
              "8   How does a processor turn an assembly instruct...   \n",
              "9   How do protons manage to overcome their mutual...   \n",
              "10  Create a comprehensive strategy that considers...   \n",
              "11  Describe how circuses originated and evolved, ...   \n",
              "12  Given the sentence \"Three men go for a ride in...   \n",
              "13  Which forces shape the Earth's orbit around th...   \n",
              "\n",
              "                                        actual_output  sbert_cosine_sim  \\\n",
              "0   The United Nations has undertaken various effo...          0.785226   \n",
              "1   Wings are not only essential for flight; they ...          0.479776   \n",
              "2   To draw a circle in matplotlib using only its ...          0.668165   \n",
              "3   Two practical and affordable strategies for en...          0.651768   \n",
              "4   1. King John faced legal issues in England in ...          0.632545   \n",
              "5   Stellar parallax is a method of measuring dist...          0.844923   \n",
              "6   Bacterial transformation involves the acquisit...          0.858031   \n",
              "7   Neurons release neurotransmitters primarily th...          0.781318   \n",
              "8   A processor executes assembly instructions as ...          0.719354   \n",
              "9   Protons can overcome their mutual repulsion be...          0.694558   \n",
              "10  Strategic Plan:\\n\\nThe goal of the comprehensi...          0.716964   \n",
              "11  1. **Traditional Traveling Circus (1500-1800s)...          0.746995   \n",
              "12  1. Identify the subject: 'Three men'\\n2. Ident...          0.824324   \n",
              "13  The Earth's orbit is shaped primarily by gravi...          0.544992   \n",
              "\n",
              "    rouge_l_recall  \n",
              "0         0.333333  \n",
              "1         0.202429  \n",
              "2         0.214953  \n",
              "3         0.215347  \n",
              "4         0.293233  \n",
              "5         0.295858  \n",
              "6         0.240437  \n",
              "7         0.136364  \n",
              "8         0.167224  \n",
              "9         0.224000  \n",
              "10        0.226374  \n",
              "11        0.118993  \n",
              "12        0.314286  \n",
              "13        0.389831  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5541fba-cd8a-4849-b46f-5a28f36d3504\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_prompt</th>\n",
              "      <th>expected_answer</th>\n",
              "      <th>modified_prompt</th>\n",
              "      <th>actual_output</th>\n",
              "      <th>sbert_cosine_sim</th>\n",
              "      <th>rouge_l_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Discuss the efforts of the United Nations to a...</td>\n",
              "      <td>The United Nations is a global organization wi...</td>\n",
              "      <td>Describe the United Nationsâ€™ efforts aimed at ...</td>\n",
              "      <td>The United Nations has undertaken various effo...</td>\n",
              "      <td>0.785226</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is a wing necessary for flight, given that...</td>\n",
              "      <td>The wing serves a crucial role in flight effic...</td>\n",
              "      <td>Why are wings essential for flight if engines ...</td>\n",
              "      <td>Wings are not only essential for flight; they ...</td>\n",
              "      <td>0.479776</td>\n",
              "      <td>0.202429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I plot a circle with matplotlib.pyplot...</td>\n",
              "      <td>The circle object that you created using `plt....</td>\n",
              "      <td>How can I draw a circle in matplotlib using on...</td>\n",
              "      <td>To draw a circle in matplotlib using only its ...</td>\n",
              "      <td>0.668165</td>\n",
              "      <td>0.214953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Discuss two practical and cost-effective ways ...</td>\n",
              "      <td>Solution 1: Implementing Renewable Energy Sour...</td>\n",
              "      <td>Examine two practical and affordable strategie...</td>\n",
              "      <td>Two practical and affordable strategies for en...</td>\n",
              "      <td>0.651768</td>\n",
              "      <td>0.215347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Explain the chain of events leading to the sig...</td>\n",
              "      <td>1. King John's rule: King John of England face...</td>\n",
              "      <td>Outline the sequence of events that led to the...</td>\n",
              "      <td>1. King John faced legal issues in England in ...</td>\n",
              "      <td>0.632545</td>\n",
              "      <td>0.293233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How is stellar parallax measured?</td>\n",
              "      <td>Stellar parallax is measured by observing the ...</td>\n",
              "      <td>How does one measure stellar parallax?</td>\n",
              "      <td>Stellar parallax is a method of measuring dist...</td>\n",
              "      <td>0.844923</td>\n",
              "      <td>0.295858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is bacterial transformation, and how does...</td>\n",
              "      <td>Bacterial transformation is a genetic modifica...</td>\n",
              "      <td>What is bacterial transformation, and through ...</td>\n",
              "      <td>Bacterial transformation involves the acquisit...</td>\n",
              "      <td>0.858031</td>\n",
              "      <td>0.240437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What triggers the release of neurotransmitters?</td>\n",
              "      <td>The axon is a long, thin projection that exten...</td>\n",
              "      <td>What causes neurons to release neurotransmitters?</td>\n",
              "      <td>Neurons release neurotransmitters primarily th...</td>\n",
              "      <td>0.781318</td>\n",
              "      <td>0.136364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does a processor execute an assembly instr...</td>\n",
              "      <td>To understand how a processor performs the add...</td>\n",
              "      <td>How does a processor turn an assembly instruct...</td>\n",
              "      <td>A processor executes assembly instructions as ...</td>\n",
              "      <td>0.719354</td>\n",
              "      <td>0.167224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How do protons overcome their repulsion and co...</td>\n",
              "      <td>When protons are initially far apart, they pos...</td>\n",
              "      <td>How do protons manage to overcome their mutual...</td>\n",
              "      <td>Protons can overcome their mutual repulsion be...</td>\n",
              "      <td>0.694558</td>\n",
              "      <td>0.224000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Develop an all-encompassing strategy that take...</td>\n",
              "      <td>To encourage the adoption of sustainable agric...</td>\n",
              "      <td>Create a comprehensive strategy that considers...</td>\n",
              "      <td>Strategic Plan:\\n\\nThe goal of the comprehensi...</td>\n",
              "      <td>0.716964</td>\n",
              "      <td>0.226374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Discuss the origin and evolution of circuses, ...</td>\n",
              "      <td>The origin of circuses can be traced back to a...</td>\n",
              "      <td>Describe how circuses originated and evolved, ...</td>\n",
              "      <td>1. **Traditional Traveling Circus (1500-1800s)...</td>\n",
              "      <td>0.746995</td>\n",
              "      <td>0.118993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Given the sentence \"Three men go for a ride in...</td>\n",
              "      <td>Step 1: Analyze the given sentence\\nThe given ...</td>\n",
              "      <td>Given the sentence \"Three men go for a ride in...</td>\n",
              "      <td>1. Identify the subject: 'Three men'\\n2. Ident...</td>\n",
              "      <td>0.824324</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What are the forces responsible for the Earth'...</td>\n",
              "      <td>The two forces responsible for the Earth's orb...</td>\n",
              "      <td>Which forces shape the Earth's orbit around th...</td>\n",
              "      <td>The Earth's orbit is shaped primarily by gravi...</td>\n",
              "      <td>0.544992</td>\n",
              "      <td>0.389831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5541fba-cd8a-4849-b46f-5a28f36d3504')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5541fba-cd8a-4849-b46f-5a28f36d3504 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5541fba-cd8a-4849-b46f-5a28f36d3504');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f984b30e-2d52-40aa-a836-6e4061ad9973\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f984b30e-2d52-40aa-a836-6e4061ad9973')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f984b30e-2d52-40aa-a836-6e4061ad9973 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"evaluate(model, tokenizer, prompts, f\\\"{CHECKPOINT_DIR}/eval\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"original_prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"How do protons overcome their repulsion and come close enough to form a nucleus, considering the short range of nuclear forces?\",\n          \"Discuss the origin and evolution of circuses, touching on significant milestones and changes in the types of acts performed throughout history.\",\n          \"Discuss the efforts of the United Nations to advance world peace.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expected_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"When protons are initially far apart, they possess sufficient kinetic energy to approach each other despite the electrostatic repulsion between them. As they get closer, they can experience a quantum mechanical phenomenon called tunneling, which allows them to pass through the energy barrier that would normally keep them apart due to their repulsion. Once they tunnel through this barrier, the strong nuclear force becomes significant, and the protons can be held together within a nucleus.\\\\n\\\\nIn some cases, this results in a temporary diproton nucleus, which is unstable. A process called beta decay occurs, where one of the protons converts into a neutron, forming a stable deuterium nucleus (deuteron). This deuteron can then participate in further nuclear fusion reactions, like those that power the sun.\",\n          \"The origin of circuses can be traced back to ancient Rome, where the first recorded circus-like event took place in 6th century BCE. The Circus Maximus, a large stadium built for chariot racing and other spectacles, was the center of Roman entertainment. However, these early events were not what we consider as modern circuses today; they mainly focused on horse and chariot races, athletic competitions, and staged battles.\\\\n\\\\nThe modern concept of the circus began to take shape in the late 18th century when Englishman Philip Astley, a former cavalry sergeant major, established the first permanent circular arena or \\\"ring\\\" for equestrian performances in London in 1768. He combined daring horsemanship with acrobatics, clowning, and music, creating a new form of popular entertainment that would become known as the circus.\\\\n\\\\nIn the early 19th century, the circus spread across Europe and North America, evolving into various forms and incorporating different acts. Tightrope walkers, jugglers, trapeze artists, and animal trainers became regular features of the circus, alongside equestrian acts and clowns. One significant milestone was the introduction of the circus tent by American showman Joshua Purdy Brown in the 1820s, which allowed circuses to travel more easily and perform in temporary venues.\\\\n\\\\nP.T. Barnum is another key figure in the evolution of the circus. In the mid-19th century, he founded the famous Barnum & Bailey Circus, which eventually merged with the Ringling Brothers Circus to create the largest traveling circus in the United States. Barnum's circus featured elaborate costumes, exotic animals, and human oddities, making it a spectacle unlike anything seen before.\\\\n\\\\nThroughout the 20th century, the circus continued to evolve, adapting to changing tastes and technologies. Traditional animal acts began to decline due to growing concerns about animal welfare, leading to an increased focus on human performances. Cirque du Soleil, founded in 1984 by Guy Lalibert\\u00e9 and Daniel Gauthier, is a prime example of this shift. The Canadian company revolutionized the circus industry with its innovative blend of acrobatics, dance, music, and theatrical elements, creating a more artistic and sophisticated form of entertainment.\\\\n\\\\nIn recent years, there has been a resurgence of interest in smaller, more intimate circuses that emphasize skilled human performers and unique acts. These contemporary circuses often incorporate elements of street performance, cabaret, and live music, offering an alternative to the large-scale productions of traditional circuses.\\\\n\\\\nIn conclusion, the origin and evolution of circuses have seen significant milestones and changes in the types of acts performed throughout history. From ancient Roman spectacles to modern-day artistic performances, the circus has continually adapted to reflect societal values and entertain audiences worldwide.\",\n          \"The United Nations is a global organization with a mission to promote international peace and security. Since its founding in 1945, the United Nations has been a major force in global diplomacy, working to resolve conflicts both on a regional and international level. The United Nations has organized peacekeeping missions and negotiated ceasefires, arms embargoes and disarmament agreements in countries around the world. The United Nations also works to provide humanitarian and economic assistance to areas affected by war, famine, and natural disasters. The United Nations also seeks to promote human rights and gender equality, uphold international law and advocate for global economic and social justice. By providing a forum for dialogue and discussion between member states, the United Nations seeks to advance dialogue and constructively address issues that have the potential to lead to conflict and war.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modified_prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"How do protons manage to overcome their mutual repulsion and get close enough to make a nucleus, given the nuclear force\\u2019s short range?\",\n          \"Describe how circuses originated and evolved, outlining important milestones and how their types of acts have changed throughout history.\",\n          \"Describe the United Nations\\u2019 efforts aimed at promoting global peace.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual_output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"Protons can overcome their mutual repulsion because they are bound by the strong nuclear force. This force is stronger at closer distances and is responsible for keeping the protons within the nucleus together, despite their mutual attraction. \\\\n\\\\nThe short range of the nuclear force means that it can only effectively bind protons together when they are within a specific distance from each other, typically on the order of picometer (pm). This is why a single proton has a significant chance of not being drawn into a nucleus on its own due to the repulsive nature of the electromagnetic forces. \\\\n\\\\nFor a nucleus to form, typically two protons are required to overcome this repulsion. Once both protons are drawn into the nucleus, additional protons are attracted due to the strong nuclear force. This is why a stable nucleus can consist of a large number of protons, such as in a neutron star.\",\n          \"1. **Traditional Traveling Circus (1500-1800s)**: Originating in Europe, traveling circuses would entertain with acrobats, jugglers, tightrope walkers, and clowns, often incorporating magic tricks. These shows moved from town to town, becoming popular street entertainment. For example, in England, the 'Ringling's' circus became famous in the late 18th and early 19th century.\\\\n\\\\n2. **Golden Age Circus (1800s-1930s)**: With advancements in technology, large rings emerged where high-wire acts became the central feature. Clowns evolved to have a more prominent role, and animal acts included elephants, horses, and lions. Performers such as the 'Strongman' and the 'Animal Act Star' became famous for their skill.\\\\n\\\\n3. **Modern Circus (1930s-present)**: Post-World War II, modern circuses incorporated more contemporary acts and styles. New attractions include aerial performances (like the \\\"Flying Trapeze\\\") and electronic elements (e.g., LED lighted tents). Moreover, trapeze arts gained prominence, while \\\"Dramatic and Darker Acts\\\" like \\\"Aerial Sideshow\\\" became popular. Today, circuses have diverse genres and locations worldwide.\\\\n\\\\nThroughout the evolution of circuses, the types of acts and performers have continuously changed and diversified, adapting to cultural, technological, and societal changes while maintaining traditional entertainment forms.\",\n          \"The United Nations has undertaken various efforts aimed at promoting global peace. Some key efforts include:\\\\n\\\\n1. Conflict Prevention and Resolution: The United Nations has developed the Preventive Diplomacy initiative to support countries at risk of violence. This program uses a range of tools, from peacekeeping to mediation, to prevent violence from breaking out in the first place. The United Nations also uses its peacekeeping operation to monitor and manage peace agreements between the warring parties. The U.N has also created various peacekeeping operations in conflict zones in order to prevent conflicts to escalate. \\\\n\\\\n2. Human Rights and Gender: The United Nations has created the Council on Human Rights (also known as Human Rights Council) to promote and protect human rights across the world. The organization aims to raise awareness of human rights abuses and promote the rights of women, children, and marginalized communities. \\\\n\\\\n3. Disarmament: The United Nations works to reduce global nuclear proliferation and reduce arms availability and increase disarmament efforts. It aims to implement disarmament treaties and agreements to create a world with reduced nuclear stockpile. \\\\n\\\\n4. Sustainable Development Goals: The U.N's Sustainable Development Goals aim to reduce conflicts by providing access to sustainable economic, social, and environmental resources to reduce inequality in the world. This is to enhance people\\u2019s participation and voices in national development decisions. \\\\n\\\\nIn conclusion, the United Nations has taken significant steps in promoting peace globally, working in conflict prevention and resolution, human rights and gender, disarmament, and sustainable development goals. These efforts are crucial in establishing a peaceful world.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sbert_cosine_sim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1099092945072933,\n        \"min\": 0.47977644205093384,\n        \"max\": 0.8580309152603149,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6945580840110779,\n          0.746995210647583,\n          0.7852263450622559\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge_l_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07665564702661375,\n        \"min\": 0.11899313501144165,\n        \"max\": 0.3898305084745763,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.224,\n          0.11899313501144165,\n          0.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving"
      ],
      "metadata": {
        "id": "g5mmZVOdu9Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_merged(\"model_full_16bit\", tokenizer, save_method = \"merged_16bit\")\n",
        "tokenizer.save_pretrained(\"model_full_16bit\")"
      ],
      "metadata": {
        "id": "gUPTMmPP4VCk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764998625650,
          "user_tz": -60,
          "elapsed": 213007,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516,
          "referenced_widgets": [
            "65799b53569b45d3a01e4316dea2f98a",
            "dc998bcb394b4f52bfde80e25dd78627",
            "95a2c287e8e04ae08871fdf48fd3dde2",
            "e237c4edd164494e8f8fe2e413551675",
            "01178f4bfef2429aafc5c57ee6bb6f3c",
            "586d82989da2400f9aae689bf249aecc",
            "181376ac040a42b988ab99a45a5a9dfd",
            "b3bb5e51daef49b6b1ebb3bbb515f2e6",
            "f2b66d48d48b4e899e807034f4503387",
            "041b04dc9f944374967db4d654855eed",
            "b46da75c544f42a791c0c509388752e7",
            "1f86de55943947dc8ecc66e113dccb0d",
            "355c4fc26d0243228101af5b9a7800a5",
            "b1b52995c3684be29e53b1331635631b",
            "19bda1b333fe4e8c83040b9b23d7192a",
            "1348f8eadc784693a046384d0b0bb94a",
            "7a0b77052e5544338ab263eaf7a33b02",
            "c3a1ad09a22440a2acf186fb3ce6d918",
            "d3001e8a104742fbb77945a02a66b9ea",
            "8cce5b2693b847f2a13321f4b0cf8fe4",
            "d6acd9e7a96a4017b4e3388d7a7024dd",
            "d4919c4c6c094c2ca839eff6226b1430",
            "805fb1e5e4004295bc0a2b96920f763e",
            "62cb47c09e994481911c70c35b5477f5",
            "71174de30de744df912328d1cb240756",
            "9ed60e77dfe34413a2d74fee9be9a26f",
            "b934f2a3bfed450fb198ec9fb910547f",
            "e636d8528975441b9ea73a8ab20cdded",
            "14a28fd3718c44dba149f3c9c7c48c26",
            "c74c18c0c45f4bc5978e5e019c052171",
            "81c120d89d174f4c89357f7bb69e81fb",
            "8bda08185cca4f18b28987944a226e18",
            "f754919503044005846294d032f924e3",
            "443fa4a1d95d4e189ebd656b306c2165",
            "2e4c00a31c844611b1ea607db8023055",
            "1384d87fe5a14f1283fcc85b2f9fa4f9",
            "cc916bea0fbe4dd9b34fd99892024460",
            "2e7db70979b9499c94593ba9cd533845",
            "2b40afbc022946e5ba2ca429fad974d6",
            "e30623b42b1542a9ab252dfc05662913",
            "4c128133afaf436dae213f3ab8e1ec10",
            "8f020a2dd696488fb15439ca4f105eb0",
            "3afab8a59be0425e94bc033268429916",
            "31dcd85a7d3544c983134d97c51ce6bd"
          ]
        },
        "outputId": "c79693f8-2c9f-4e0c-f06f-d6334293fe13"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/890 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65799b53569b45d3a01e4316dea2f98a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f86de55943947dc8ecc66e113dccb0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking cache directory for required files...\n",
            "Cache check failed: model-00001-of-00002.safetensors not found in local cache.\n",
            "Not all required files found in cache. Will proceed with downloading.\n",
            "Checking cache directory for required files...\n",
            "Cache check failed: tokenizer.model not found in local cache.\n",
            "Not all required files found in cache. Will proceed with downloading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Preparing safetensor model files:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "805fb1e5e4004295bc0a2b96920f763e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rUnsloth: Preparing safetensor model files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [01:26<01:26, 86.07s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "443fa4a1d95d4e189ebd656b306c2165"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:46<00:00, 53.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: tokenizer.model not found (this is OK for non-SentencePiece models)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:42<00:00, 51.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merge process complete. Saved to `/content/model_full_16bit`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model_full_16bit/tokenizer_config.json',\n",
              " 'model_full_16bit/special_tokens_map.json',\n",
              " 'model_full_16bit/chat_template.jinja',\n",
              " 'model_full_16bit/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install pciutils build-essential cmake curl libcurl4-openssl-dev -y\n",
        "if not os.path.isdir(\"llama.cpp\"):\n",
        "    !git clone https://github.com/ggerganov/llama.cpp.git\n",
        "else:\n",
        "    print(\"llama.cpp already present.\")\n",
        "!pip install -U \"transformers\" \"huggingface_hub\"\n",
        "!mkdir -p llama.cpp/build && cd llama.cpp/build && cmake .. && cmake --build . --config Release --target llama-quantize llama-cli llama-gguf-split llama-mtmd-cli"
      ],
      "metadata": {
        "id": "oaZ-r5OH4-uY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764999099402,
          "user_tz": -60,
          "elapsed": 473751,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "950ffbd7-86de-405f-e63d-b17f383f7fe4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.92.22)] [Connecting to security.ub\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,201 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,842 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,509 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.8 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,571 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,281 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,081 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,901 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Fetched 37.8 MB in 4s (10.5 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.21).\n",
            "libcurl4-openssl-dev is already the newest version (7.81.0-1ubuntu1.21).\n",
            "The following additional packages will be installed:\n",
            "  libpci3 pci.ids\n",
            "The following NEW packages will be installed:\n",
            "  libpci3 pci.ids pciutils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 65 not upgraded.\n",
            "Need to get 343 kB of archives.\n",
            "After this operation, 1,581 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 pci.ids all 0.0~2022.01.22-1ubuntu0.1 [251 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpci3 amd64 1:3.7.0-6 [28.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 pciutils amd64 1:3.7.0-6 [63.6 kB]\n",
            "Fetched 343 kB in 1s (252 kB/s)\n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1ubuntu0.1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking pciutils (1:3.7.0-6) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up pciutils (1:3.7.0-6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 70963, done.\u001b[K\n",
            "remote: Counting objects: 100% (341/341), done.\u001b[K\n",
            "remote: Compressing objects: 100% (183/183), done.\u001b[K\n",
            "remote: Total 70963 (delta 227), reused 158 (delta 158), pack-reused 70622 (from 2)\u001b[K\n",
            "Receiving objects: 100% (70963/70963), 225.17 MiB | 30.52 MiB/s, done.\n",
            "Resolving deltas: 100% (51178/51178), done.\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-1.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.2\n",
            "    Uninstalling transformers-4.57.2:\n",
            "      Successfully uninstalled transformers-4.57.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth-zoo 2025.11.6 requires transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.57.2,>=4.51.3, but you have transformers 4.57.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed transformers-4.57.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "36a84346ccd34b4a9cb2669bdf7393c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[0mCMAKE_BUILD_TYPE=Release\u001b[0m\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "-- The ASM compiler identification is GNU\n",
            "-- Found assembler: /usr/bin/cc\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- GGML_SYSTEM_ARCH: x86\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP: TRUE (found version \"4.5\")\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- ggml version: 0.9.4\n",
            "-- ggml commit:  d8c0a7b08\n",
            "-- Found CURL: /usr/lib/x86_64-linux-gnu/libcurl.so (found version \"7.81.0\")\n",
            "-- Configuring done (2.4s)\n",
            "-- Generating done (0.4s)\n",
            "-- Build files have been written to: /content/llama.cpp/build\n",
            "[  0%] \u001b[32mBuilding CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\u001b[0m\n",
            "[  0%] Built target build_info\n",
            "[  0%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
            "[  0%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-base.so\u001b[0m\n",
            "[  4%] Built target ggml-base\n",
            "[  6%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-cpu.so\u001b[0m\n",
            "[ 12%] Built target ggml-cpu\n",
            "[ 14%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml.so\u001b[0m\n",
            "[ 14%] Built target ggml\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-cparams.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-saver.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/afmoe.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/apertus.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/arcee.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/arctic.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/arwkv7.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/baichuan.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/bailingmoe.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/bailingmoe2.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/bert.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/bitnet.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/bloom.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/chameleon.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/chatglm.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/codeshell.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/cogvlm.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/cohere2-iswa.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/command-r.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/dbrx.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/deci.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/deepseek.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/deepseek2.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/dots1.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/dream.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/ernie4-5-moe.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/ernie4-5.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/exaone.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/exaone4.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/falcon-h1.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/falcon.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/gemma-embedding.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/gemma.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/gemma2-iswa.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/gemma3-iswa.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/gemma3n-iswa.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/glm4-moe.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/glm4.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/gpt2.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/gptneox.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/granite-hybrid.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/granite.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/grok.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/grovemoe.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/hunyuan-dense.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/hunyuan-moe.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/internlm2.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/jais.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/jamba.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/lfm2.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/llada-moe.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/llada.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/llama-iswa.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/llama.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/mamba.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/minicpm3.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/minimax-m2.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/mpt.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/nemotron-h.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/nemotron.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/neo-bert.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/olmo.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/olmo2.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/olmoe.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/openai-moe-iswa.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/openelm.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/orion.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/pangu-embedded.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/phi2.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/phi3.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/plamo.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/plamo2.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/plm.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/qwen.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/qwen2.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/qwen2moe.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/qwen2vl.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/qwen3.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/qwen3vl.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/qwen3vl-moe.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/qwen3moe.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/qwen3next.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/refact.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/rnd1.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/rwkv6-base.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/rwkv6.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/rwkv6qwen2.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/rwkv7-base.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/rwkv7.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/seed-oss.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/smallthinker.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/smollm3.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/stablelm.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/starcoder.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/starcoder2.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/t5-dec.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/t5-enc.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/wavtokenizer-dec.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/xverse.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/mistral3.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/models/graph-context-mamba.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX shared library ../bin/libllama.so\u001b[0m\n",
            "[ 87%] Built target llama\n",
            "[ 87%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/arg.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat-parser.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat-parser-xml-toolcall.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat-peg-parser.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/console.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/download.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-partial.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/llguidance.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/log.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/peg-parser.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/regex-partial.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/sampling.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/speculative.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/unicode.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n",
            "[ 97%] Built target common\n",
            "[100%] \u001b[32mBuilding CXX object tools/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-quantize\u001b[0m\n",
            "[100%] Built target llama-quantize\n",
            "[  0%] Built target build_info\n",
            "[  4%] Built target ggml-base\n",
            "[ 13%] Built target ggml-cpu\n",
            "[ 15%] Built target ggml\n",
            "[ 89%] Built target llama\n",
            "[100%] Built target common\n",
            "[100%] \u001b[32mBuilding CXX object tools/main/CMakeFiles/llama-cli.dir/main.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cli\u001b[0m\n",
            "[100%] Built target llama-cli\n",
            "[  0%] Built target build_info\n",
            "[  4%] Built target ggml-base\n",
            "[ 13%] Built target ggml-cpu\n",
            "[ 15%] Built target ggml\n",
            "[ 89%] Built target llama\n",
            "[100%] Built target common\n",
            "[100%] \u001b[32mBuilding CXX object tools/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-split\u001b[0m\n",
            "[100%] Built target llama-gguf-split\n",
            "[  4%] Built target ggml-base\n",
            "[ 12%] Built target ggml-cpu\n",
            "[ 14%] Built target ggml\n",
            "[ 87%] Built target llama\n",
            "[ 87%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libmtmd.so\u001b[0m\n",
            "[ 89%] Built target mtmd\n",
            "[ 89%] Built target build_info\n",
            "[100%] Built target common\n",
            "[100%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-mtmd-cli\u001b[0m\n",
            "[100%] Built target llama-mtmd-cli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gguf_f16_file_name = \"/content/Model-F16.gguf\"\n",
        "gguf_q4km_file_name = f\"{CHECKPOINT_DIR}/Model-Q4_K_M.gguf\"\n",
        "!python llama.cpp/convert_hf_to_gguf.py ./model_full_16bit/ --outfile {gguf_f16_file_name} --outtype f16\n",
        "!cd llama.cpp/build/bin && ./llama-quantize {gguf_f16_file_name} {gguf_q4km_file_name} q4_k_m"
      ],
      "metadata": {
        "id": "X8jQ61eUF0fG",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1764999670197,
          "user_tz": -60,
          "elapsed": 570779,
          "user": {
            "displayName": "Paul Kilian",
            "userId": "12769555656558612045"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee8fca7-b1ff-41a0-95ad-2273c31f6b3e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:hf-to-gguf:Loading model: model_full_16bit\n",
            "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: indexing model part 'model-00001-of-00002.safetensors'\n",
            "INFO:hf-to-gguf:gguf: indexing model part 'model-00002-of-00002.safetensors'\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> F16, shape = {3072, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> F16, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 131072\n",
            "INFO:hf-to-gguf:gguf: embedding length = 3072\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
            "INFO:hf-to-gguf:gguf: head count = 24\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "WARNING:gguf.vocab:Unknown separator token '<|begin_of_text|>' in TemplateProcessing<pair>\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128004\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_sep_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 July 2024\" %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content'] %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\n",
            "\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\n",
            "\n",
            "\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\n",
            "\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\n",
            "\n",
            "\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\n",
            "\n",
            "\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\n",
            "\n",
            "\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content'] %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\n",
            "\n",
            "\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\n",
            "\n",
            "\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\n",
            "\n",
            "\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\n",
            "\n",
            "\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}\n",
            "{%- endif %}\n",
            "\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/Model-F16.gguf: n_tensors = 255, total_size = 6.4G\n",
            "Writing: 100% 6.43G/6.43G [03:14<00:00, 33.1Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/Model-F16.gguf\n",
            "main: build = 7294 (d8c0a7b08)\n",
            "main: built with GNU 11.4.0 for Linux x86_64\n",
            "main: quantizing '/content/Model-F16.gguf' to '/content/drive/MyDrive/unsloth/Llama-3.2-3B-Instruct-bnb-4bit/Model-Q4_K_M.gguf' as Q4_K_M\n",
            "llama_model_loader: loaded meta data with 29 key-value pairs and 255 tensors from /content/Model-F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Model_Full_16Bit\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
            "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ä  Ä \", \"Ä  Ä Ä Ä \", \"Ä Ä  Ä Ä \", \"...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  27:               tokenizer.ggml.add_sep_token bool             = false\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - type  f32:   58 tensors\n",
            "llama_model_loader: - type  f16:  197 tensors\n",
            "llama_model_quantize_impl: n_layer_all = 28, n_layer_recr = 0, pruned_attention_w = 0\n",
            "[   1/ 255]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[   2/ 255]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MiB\n",
            "[   3/ 255]                    token_embd.weight - [ 3072, 128256,     1,     1], type =    f16, converting to q6_K .. size =   751.50 MiB ->   308.23 MiB\n",
            "[   4/ 255]                  blk.0.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[   5/ 255]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[   6/ 255]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[   7/ 255]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[   8/ 255]                  blk.0.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[   9/ 255]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  10/ 255]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  11/ 255]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  12/ 255]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  13/ 255]                  blk.1.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  14/ 255]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  15/ 255]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  16/ 255]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  17/ 255]                  blk.1.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  18/ 255]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  19/ 255]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  20/ 255]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  21/ 255]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  22/ 255]                  blk.2.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  23/ 255]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  24/ 255]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  25/ 255]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  26/ 255]                  blk.2.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  27/ 255]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  28/ 255]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  29/ 255]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  30/ 255]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  31/ 255]                  blk.3.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  32/ 255]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  33/ 255]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  34/ 255]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  35/ 255]                  blk.3.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  36/ 255]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  37/ 255]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  38/ 255]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  39/ 255]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  40/ 255]                  blk.4.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  41/ 255]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  42/ 255]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  43/ 255]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  44/ 255]                  blk.4.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  45/ 255]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  46/ 255]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  47/ 255]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  48/ 255]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  49/ 255]                  blk.5.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  50/ 255]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  51/ 255]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  52/ 255]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  53/ 255]                  blk.5.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  54/ 255]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  55/ 255]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  56/ 255]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  57/ 255]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  58/ 255]                  blk.6.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  59/ 255]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  60/ 255]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  61/ 255]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  62/ 255]                  blk.6.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  63/ 255]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  64/ 255]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  65/ 255]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  66/ 255]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  67/ 255]                  blk.7.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  68/ 255]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  69/ 255]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  70/ 255]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  71/ 255]                  blk.7.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  72/ 255]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  73/ 255]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  74/ 255]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  75/ 255]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  76/ 255]                  blk.8.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  77/ 255]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  78/ 255]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  79/ 255]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  80/ 255]                  blk.8.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[  81/ 255]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  82/ 255]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  83/ 255]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  84/ 255]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  85/ 255]                  blk.9.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  86/ 255]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  87/ 255]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  88/ 255]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  89/ 255]                  blk.9.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  90/ 255]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  91/ 255]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  92/ 255]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  93/ 255]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  94/ 255]                 blk.10.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  95/ 255]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[  96/ 255]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  97/ 255]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  98/ 255]                 blk.10.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[  99/ 255]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 100/ 255]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 101/ 255]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 102/ 255]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 103/ 255]                 blk.11.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 104/ 255]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 105/ 255]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 106/ 255]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 107/ 255]                 blk.11.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 108/ 255]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 109/ 255]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 110/ 255]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 111/ 255]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 112/ 255]                 blk.12.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 113/ 255]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 114/ 255]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 115/ 255]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 116/ 255]                 blk.12.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 117/ 255]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 118/ 255]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 119/ 255]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 120/ 255]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 121/ 255]                 blk.13.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 122/ 255]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 123/ 255]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 124/ 255]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 125/ 255]                 blk.13.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 126/ 255]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 127/ 255]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 128/ 255]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 129/ 255]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 130/ 255]                 blk.14.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 131/ 255]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 132/ 255]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 133/ 255]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 134/ 255]                 blk.14.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 135/ 255]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 136/ 255]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 137/ 255]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 138/ 255]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 139/ 255]                 blk.15.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 140/ 255]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 141/ 255]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 142/ 255]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 143/ 255]                 blk.15.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 144/ 255]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 145/ 255]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 146/ 255]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 147/ 255]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 148/ 255]                 blk.16.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 149/ 255]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 150/ 255]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 151/ 255]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 152/ 255]                 blk.16.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 153/ 255]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 154/ 255]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 155/ 255]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 156/ 255]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 157/ 255]                 blk.17.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 158/ 255]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 159/ 255]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 160/ 255]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 161/ 255]                 blk.17.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 162/ 255]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 163/ 255]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 164/ 255]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 165/ 255]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 166/ 255]                 blk.18.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 167/ 255]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 168/ 255]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 169/ 255]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 170/ 255]                 blk.18.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 171/ 255]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 172/ 255]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 173/ 255]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 174/ 255]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 175/ 255]                 blk.19.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 176/ 255]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 177/ 255]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 178/ 255]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 179/ 255]                 blk.19.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 180/ 255]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 181/ 255]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 182/ 255]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 183/ 255]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 184/ 255]                 blk.20.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 185/ 255]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 186/ 255]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 187/ 255]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 188/ 255]                 blk.20.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 189/ 255]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 190/ 255]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 191/ 255]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 192/ 255]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 193/ 255]                 blk.21.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 194/ 255]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 195/ 255]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 196/ 255]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 197/ 255]                 blk.21.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 198/ 255]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 199/ 255]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 200/ 255]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 201/ 255]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 202/ 255]                 blk.22.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 203/ 255]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 204/ 255]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 205/ 255]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 206/ 255]                 blk.22.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 207/ 255]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 208/ 255]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 209/ 255]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 210/ 255]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 211/ 255]                 blk.23.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 212/ 255]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 213/ 255]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 214/ 255]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 215/ 255]                 blk.23.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 216/ 255]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 217/ 255]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 218/ 255]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 219/ 255]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 220/ 255]                 blk.24.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 221/ 255]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 222/ 255]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 223/ 255]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 224/ 255]                 blk.24.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 225/ 255]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 226/ 255]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 227/ 255]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 228/ 255]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 229/ 255]                 blk.25.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 230/ 255]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 231/ 255]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 232/ 255]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 233/ 255]                 blk.25.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 234/ 255]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 235/ 255]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 236/ 255]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 237/ 255]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 238/ 255]                 blk.26.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 239/ 255]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 240/ 255]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 241/ 255]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 242/ 255]                 blk.26.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 243/ 255]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 244/ 255]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 245/ 255]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 246/ 255]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 247/ 255]                 blk.27.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
            "[ 248/ 255]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 249/ 255]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 250/ 255]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 251/ 255]                 blk.27.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
            "[ 252/ 255]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 253/ 255]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 254/ 255]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
            "[ 255/ 255]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "llama_model_quantize_impl: model size  =  6128.17 MiB\n",
            "llama_model_quantize_impl: quant size  =  1918.35 MiB\n",
            "\n",
            "main: quantize time = 344894.39 ms\n",
            "main:    total time = 344894.39 ms\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [
        {
          "file_id": "https://github.com/bakalis/llm_fine_tuning/blob/main/llama_fine_tuning.ipynb",
          "timestamp": 1764176750069
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}